import os
import sys
import glob
from datetime import datetime
from typing import List, Dict

import pandas as pd

# å…è®¸è„šæœ¬ç‹¬ç«‹è¿è¡Œï¼šå°†å½“å‰ç›®å½•åŠ å…¥sys.pathåä½¿ç”¨ç»å¯¹å¯¼å…¥
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
if CURRENT_DIR not in sys.path:
    sys.path.insert(0, CURRENT_DIR)
from shishi_data_yujing_gz import WasteIncinerationWarningSystemNingbo


def is_input_excel(file_path: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºéœ€è¦å¤„ç†çš„è¾“å…¥Excelï¼Œæ’é™¤å·²ç”Ÿæˆçš„æŠ¥å‘Š/ç»Ÿè®¡æ–‡ä»¶ã€‚"""
    lower = os.path.basename(file_path).lower()
    
    # å¿…é¡»æ˜¯xlsxæ–‡ä»¶
    if not lower.endswith('.xlsx'):
        return False
    
    # æ’é™¤æ˜ç¡®çš„è¾“å‡ºæ–‡ä»¶ï¼ˆæ›´ç²¾ç¡®çš„æ’é™¤è§„åˆ™ï¼‰
    exclude_keywords = [
        'é¢„è­¦æŠ¥è­¦æŠ¥å‘Š_',      # æˆ‘ä»¬ç”Ÿæˆçš„é¢„è­¦æŠ¥è­¦æŠ¥å‘Š
        'é¢„è­¦æŠ¥è­¦ç»Ÿè®¡_',      # æˆ‘ä»¬ç”Ÿæˆçš„ç»Ÿè®¡æ–‡ä»¶  
        'æ‰¹é‡æ±‡æ€»_',          # æ‰¹é‡å¤„ç†ç”Ÿæˆçš„æ±‡æ€»æ–‡ä»¶
        '_äº‹ä»¶æ˜ç»†',          # æ‰¹é‡äº‹ä»¶æ˜ç»†
        '_ç»Ÿè®¡.xlsx',        # æ‰¹é‡ç»Ÿè®¡Excel
        '_å„æ–‡ä»¶æ±‡æ€»'         # å„æ–‡ä»¶æ±‡æ€»
    ]
    
    # åªæœ‰å½“æ–‡ä»¶åæ˜ç¡®åŒ…å«è¿™äº›å…³é”®è¯æ—¶æ‰æ’é™¤
    for keyword in exclude_keywords:
        if keyword in lower:
            return False
    
    return True


def summarize_events(df: pd.DataFrame) -> Dict[str, pd.Series]:
    """å¯¹å•ä¸ªæ–‡ä»¶çš„äº‹ä»¶DataFrameåšç®€å•ç»Ÿè®¡æ±‡æ€»ã€‚"""
    if df.empty:
        return {
            'type_stats': pd.Series(dtype=int),
            'event_stats': pd.Series(dtype=int),
            'furnace_stats': pd.Series(dtype=int),
        }
    type_stats = df['é¢„è­¦/æŠ¥è­¦ç±»å‹'].value_counts()
    event_stats = df['é¢„è­¦/æŠ¥è­¦äº‹ä»¶'].value_counts()
    furnace_stats = df['ç‚‰å·'].value_counts().sort_index()
    return {
        'type_stats': type_stats,
        'event_stats': event_stats,
        'furnace_stats': furnace_stats,
    }


def process_directory(input_dir: str, output_dir: str) -> None:
    """æ‰¹é‡å¤„ç†ç›®å½•ä¸­çš„Excel/CSVæ–‡ä»¶ï¼Œå¹¶è¾“å‡ºæ•´ä½“æ±‡æ€»ã€‚"""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    print(f"ğŸ” æ­£åœ¨æœç´¢ç›®å½•: {input_dir}")
    
    # æ‰©å±•æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼šxlsxå’Œcsv
    patterns = [
        os.path.join(input_dir, '**', '*.xlsx'),
        os.path.join(input_dir, '**', '*.csv')
    ]
    
    all_found_files = []
    for pattern in patterns:
        found = glob.glob(pattern, recursive=True)
        all_found_files.extend(found)
    
    print(f"ğŸ“ å‘ç°æ‰€æœ‰Excel/CSVæ–‡ä»¶ {len(all_found_files)} ä¸ª:")
    for f in sorted(all_found_files):
        print(f"   - {f}")
    
    # è¿‡æ»¤å‡ºéœ€è¦å¤„ç†çš„æ•°æ®æ–‡ä»¶
    files = []
    excluded_files = []
    
    for f in all_found_files:
        # æ’é™¤è¾“å‡ºç›®å½•ä¸­çš„æ–‡ä»¶
        if output_dir in f:
            excluded_files.append((f, "åœ¨è¾“å‡ºç›®å½•ä¸­"))
            continue
            
        # æ’é™¤__pycache__ç­‰ç³»ç»Ÿç›®å½•
        if '__pycache__' in f or '.git' in f:
            excluded_files.append((f, "ç³»ç»Ÿç›®å½•"))
            continue
            
        # å¯¹äºxlsxæ–‡ä»¶ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºè¾“å…¥æ–‡ä»¶
        if f.lower().endswith('.xlsx'):
            if is_input_excel(f):
                files.append(f)
            else:
                excluded_files.append((f, "è¯†åˆ«ä¸ºè¾“å‡ºæ–‡ä»¶"))
        # CSVæ–‡ä»¶ç›´æ¥åŒ…å«ï¼ˆæ›´å®½æ¾çš„ç­–ç•¥ï¼‰
        elif f.lower().endswith('.csv'):
            # ç®€å•æ’é™¤æ˜æ˜¾çš„è¾“å‡ºæ–‡ä»¶
            basename = os.path.basename(f).lower()
            if any(keyword in basename for keyword in ['é¢„è­¦æŠ¥è­¦', 'æ‰¹é‡æ±‡æ€»', 'ç»Ÿè®¡']):
                excluded_files.append((f, "è¯†åˆ«ä¸ºè¾“å‡ºæ–‡ä»¶"))
            else:
                files.append(f)
    
    print(f"\nğŸ“‹ å¾…å¤„ç†æ–‡ä»¶ {len(files)} ä¸ª:")
    for f in sorted(files):
        print(f"   âœ… {f}")
    
    if excluded_files:
        print(f"\nğŸš« å·²æ’é™¤æ–‡ä»¶ {len(excluded_files)} ä¸ª:")
        for f, reason in excluded_files:
            print(f"   âŒ {f} ({reason})")

    if not files:
        print(f"\nâš ï¸  æœªåœ¨ {input_dir} å‘ç°å¾…å¤„ç†çš„æ•°æ®æ–‡ä»¶")
        print("ğŸ’¡ æç¤º: è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„å’Œæ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®")
        return

    system = WasteIncinerationWarningSystemNingbo()

    all_events: List[pd.DataFrame] = []
    file_level_summary: List[Dict] = []

    print(f"\nğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {len(files)} ä¸ªæ–‡ä»¶...")
    successful_count = 0
    failed_count = 0
    
    for idx, file_path in enumerate(sorted(files)):
        file_name = os.path.basename(file_path)
        print(f"\n[{idx+1}/{len(files)}] ğŸ“„ å¤„ç†: {file_name}")
        print(f"   è·¯å¾„: {file_path}")
        
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¯è¯»
            if not os.path.exists(file_path):
                raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
            if os.path.getsize(file_path) == 0:
                raise ValueError(f"æ–‡ä»¶ä¸ºç©º: {file_path}")
            
            # å¤„ç†æ•°æ®
            df = system.process_data(file_path, output_dir)
            
            if df is not None and not df.empty:
                df = df.copy()
                df.insert(0, 'æ•°æ®æ–‡ä»¶', file_name)
                all_events.append(df)

                stats = summarize_events(df)
                file_level_summary.append({
                    'æ•°æ®æ–‡ä»¶': file_name,
                    'æ€»äº‹ä»¶æ•°': len(df),
                    'é¢„è­¦æ•°': int(stats['type_stats'].get('é¢„è­¦', 0)),
                    'æŠ¥è­¦æ•°': int(stats['type_stats'].get('æŠ¥è­¦', 0)),
                    'çŠ¶æ€': 'æˆåŠŸ'
                })
                successful_count += 1
                print(f"   âœ… æˆåŠŸå¤„ç†ï¼Œå‘ç° {len(df)} æ¡é¢„è­¦/æŠ¥è­¦äº‹ä»¶")
            else:
                file_level_summary.append({
                    'æ•°æ®æ–‡ä»¶': file_name,
                    'æ€»äº‹ä»¶æ•°': 0,
                    'é¢„è­¦æ•°': 0,
                    'æŠ¥è­¦æ•°': 0,
                    'çŠ¶æ€': 'æˆåŠŸï¼ˆæ— äº‹ä»¶ï¼‰'
                })
                successful_count += 1
                print(f"   âœ… æˆåŠŸå¤„ç†ï¼Œæœªå‘ç°é¢„è­¦/æŠ¥è­¦äº‹ä»¶")
                
        except Exception as exc:
            failed_count += 1
            error_msg = str(exc)
            print(f"   âŒ å¤„ç†å¤±è´¥: {error_msg}")
            file_level_summary.append({
                'æ•°æ®æ–‡ä»¶': file_name,
                'æ€»äº‹ä»¶æ•°': -1,
                'é¢„è­¦æ•°': -1,
                'æŠ¥è­¦æ•°': -1,
                'çŠ¶æ€': 'å¤±è´¥',
                'é”™è¯¯ä¿¡æ¯': error_msg,
            })
    
    print(f"\nğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆ:")
    print(f"   âœ… æˆåŠŸ: {successful_count} ä¸ªæ–‡ä»¶")
    print(f"   âŒ å¤±è´¥: {failed_count} ä¸ªæ–‡ä»¶")
    print(f"   ğŸ“ˆ æ€»è®¡: {len(files)} ä¸ªæ–‡ä»¶")

    # ç”Ÿæˆæ±‡æ€»è¾“å‡º
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    base_name = f"å®æ³¢ä¸–è´¸æ‰¹é‡æ±‡æ€»_{timestamp}"

    # æ€»è¡¨ï¼šåˆå¹¶æ‰€æœ‰äº‹ä»¶
    if all_events:
        all_df = pd.concat(all_events, ignore_index=True)
        combined_csv = os.path.join(output_dir, f"{base_name}_äº‹ä»¶æ˜ç»†.csv")
        all_df.to_csv(combined_csv, index=False, encoding='utf-8-sig')
        print(f"âœ… æ‰¹é‡äº‹ä»¶æ˜ç»†å·²ä¿å­˜: {combined_csv}")

        # ç»Ÿè®¡ï¼šæ•´ä½“ç±»å‹ç»Ÿè®¡/äº‹ä»¶ç»Ÿè®¡/å„ç‚‰ç»Ÿè®¡
        overall_type = all_df['é¢„è­¦/æŠ¥è­¦ç±»å‹'].value_counts().rename('æ•°é‡')
        overall_event = all_df['é¢„è­¦/æŠ¥è­¦äº‹ä»¶'].value_counts().rename('æ•°é‡')
        overall_furnace = all_df['ç‚‰å·'].value_counts().sort_index().rename('æ•°é‡')

        # è¾“å‡ºåˆ°ä¸€ä¸ªExcelä¸­å¤šsheet
        combined_xlsx = os.path.join(output_dir, f"{base_name}_ç»Ÿè®¡.xlsx")
        with pd.ExcelWriter(combined_xlsx, engine='openpyxl') as writer:
            all_df.to_excel(writer, sheet_name='äº‹ä»¶æ˜ç»†', index=False)
            overall_type.to_frame().to_excel(writer, sheet_name='ç±»å‹ç»Ÿè®¡')
            overall_event.to_frame().to_excel(writer, sheet_name='äº‹ä»¶ç»Ÿè®¡')
            overall_furnace.to_frame().to_excel(writer, sheet_name='å„ç‚‰ç»Ÿè®¡')

        print(f"âœ… æ‰¹é‡ç»Ÿè®¡Excelå·²ä¿å­˜: {combined_xlsx}")

    # æ–‡ä»¶çº§ç®€è¡¨
    if file_level_summary:
        summary_df = pd.DataFrame(file_level_summary)
        summary_csv = os.path.join(output_dir, f"{base_name}_å„æ–‡ä»¶æ±‡æ€».csv")
        summary_df.to_csv(summary_csv, index=False, encoding='utf-8-sig')
        print(f"âœ… å„æ–‡ä»¶æ±‡æ€»å·²ä¿å­˜: {summary_csv}")


def main():
    DEFAULT_INPUT_DIR = os.path.join('å®å¾·ä¸–è´¸')
    DEFAULT_OUTPUT_DIR = os.path.join('å®å¾·ä¸–è´¸', 'é¢„è­¦æ–‡ä»¶è¾“å‡º')

    print("=" * 60)
    print("ğŸ­ å®æ³¢ä¸–è´¸åƒåœ¾ç„šçƒ§é¢„è­¦æŠ¥è­¦ç³»ç»Ÿ - æ‰¹é‡å¤„ç†å·¥å…·")
    print("=" * 60)

    if len(sys.argv) >= 2:
        input_dir = sys.argv[1]
        output_dir = sys.argv[2] if len(sys.argv) > 2 else DEFAULT_OUTPUT_DIR
        print("ğŸ“ ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°:")
    else:
        print("ğŸš€ ä½¿ç”¨é»˜è®¤é…ç½®:")
        print("ğŸ’¡ æç¤º: å¯ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šç›®å½•")
        print("   ç”¨æ³•: python batch_process.py <è¾“å…¥ç›®å½•> [è¾“å‡ºç›®å½•]")
        input_dir = DEFAULT_INPUT_DIR
        output_dir = DEFAULT_OUTPUT_DIR

    print(f"ğŸ“‚ è¾“å…¥ç›®å½•: {os.path.abspath(input_dir)}")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {os.path.abspath(output_dir)}")
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_dir):
        print(f"âŒ é”™è¯¯: è¾“å…¥ç›®å½•ä¸å­˜åœ¨ - {input_dir}")
        print("ğŸ’¡ è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®")
        return
    
    print(f"\nğŸ”„ æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: .xlsx, .csv")
    print(f"ğŸ” æœç´¢æ–¹å¼: é€’å½’æœç´¢æ‰€æœ‰å­ç›®å½•")
    
    try:
        process_directory(input_dir, output_dir)
        print(f"\nğŸ‰ æ‰¹é‡å¤„ç†ä»»åŠ¡å®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶ä¿å­˜åœ¨: {os.path.abspath(output_dir)}")
    except Exception as e:
        print(f"\nâŒ æ‰¹é‡å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()


