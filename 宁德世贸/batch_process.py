import os
import sys
import glob
from datetime import datetime
from typing import List, Dict

import pandas as pd

# å…è®¸è„šæœ¬ç‹¬ç«‹è¿è¡Œï¼šå°†å½“å‰ç›®å½•åŠ å…¥sys.pathåä½¿ç”¨ç»å¯¹å¯¼å…¥
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
if CURRENT_DIR not in sys.path:
    sys.path.insert(0, CURRENT_DIR)
from shishi_data_yujing_gz import WasteIncinerationWarningSystemNingbo


def is_input_excel(file_path: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºéœ€è¦å¤„ç†çš„è¾“å…¥Excelï¼Œæ’é™¤å·²ç”Ÿæˆçš„æŠ¥å‘Š/ç»Ÿè®¡æ–‡ä»¶ã€‚"""
    lower = os.path.basename(file_path).lower()
    if not lower.endswith('.xlsx'):
        return False
    # æ’é™¤æˆ‘ä»¬ç”Ÿæˆçš„æŠ¥å‘Š/ç»Ÿè®¡
    exclude_keywords = [
        'é¢„è­¦æŠ¥è­¦æŠ¥å‘Š', 'é¢„è­¦æŠ¥è­¦ç»Ÿè®¡', 'æ‰¹é‡æ±‡æ€»'
    ]
    return not any(k in lower for k in exclude_keywords)


def summarize_events(df: pd.DataFrame) -> Dict[str, pd.Series]:
    """å¯¹å•ä¸ªæ–‡ä»¶çš„äº‹ä»¶DataFrameåšç®€å•ç»Ÿè®¡æ±‡æ€»ã€‚"""
    if df.empty:
        return {
            'type_stats': pd.Series(dtype=int),
            'event_stats': pd.Series(dtype=int),
            'furnace_stats': pd.Series(dtype=int),
        }
    type_stats = df['é¢„è­¦/æŠ¥è­¦ç±»å‹'].value_counts()
    event_stats = df['é¢„è­¦/æŠ¥è­¦äº‹ä»¶'].value_counts()
    furnace_stats = df['ç‚‰å·'].value_counts().sort_index()
    return {
        'type_stats': type_stats,
        'event_stats': event_stats,
        'furnace_stats': furnace_stats,
    }


def process_directory(input_dir: str, output_dir: str) -> None:
    """æ‰¹é‡å¤„ç†ç›®å½•ä¸­çš„.xlsxæ–‡ä»¶ï¼Œå¹¶è¾“å‡ºæ•´ä½“æ±‡æ€»ã€‚"""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # é€’å½’æŸ¥æ‰¾å­ç›®å½•ï¼ˆå¦‚ 2025å¹´1æœˆã€2025å¹´2æœˆ ...ï¼‰ä¸­çš„ .xlsx æ•°æ®æ–‡ä»¶
    pattern = os.path.join(input_dir, '**', '*.xlsx')
    files = [
        f for f in glob.glob(pattern, recursive=True)
        if is_input_excel(f)
        and ('é¢„è­¦æ–‡ä»¶è¾“å‡º' not in f)
        and ('__pycache__' not in f)
    ]

    if not files:
        print(f"æœªåœ¨ {input_dir} å‘ç°å¾…å¤„ç†çš„.xlsxæ•°æ®æ–‡ä»¶")
        return

    system = WasteIncinerationWarningSystemNingbo()

    all_events: List[pd.DataFrame] = []
    file_level_summary: List[Dict] = []

    print(f"å…±å‘ç° {len(files)} ä¸ªxlsxæ–‡ä»¶ï¼Œå¼€å§‹æ‰¹é‡å¤„ç†...")
    for idx, file_path in enumerate(sorted(files)):
        print(f"[{idx+1}/{len(files)}] å¤„ç†: {file_path}")
        try:
            df = system.process_data(file_path, output_dir)
            if df is not None and not df.empty:
                df = df.copy()
                df.insert(0, 'æ•°æ®æ–‡ä»¶', os.path.basename(file_path))
                all_events.append(df)

                stats = summarize_events(df)
                file_level_summary.append({
                    'æ•°æ®æ–‡ä»¶': os.path.basename(file_path),
                    'æ€»äº‹ä»¶æ•°': len(df),
                    'é¢„è­¦æ•°': int(stats['type_stats'].get('é¢„è­¦', 0)),
                    'æŠ¥è­¦æ•°': int(stats['type_stats'].get('æŠ¥è­¦', 0)),
                })
            else:
                file_level_summary.append({
                    'æ•°æ®æ–‡ä»¶': os.path.basename(file_path),
                    'æ€»äº‹ä»¶æ•°': 0,
                    'é¢„è­¦æ•°': 0,
                    'æŠ¥è­¦æ•°': 0,
                })
        except Exception as exc:
            print(f"âŒ å¤„ç†å¤±è´¥: {file_path} -> {exc}")
            file_level_summary.append({
                'æ•°æ®æ–‡ä»¶': os.path.basename(file_path),
                'æ€»äº‹ä»¶æ•°': -1,
                'é¢„è­¦æ•°': -1,
                'æŠ¥è­¦æ•°': -1,
                'é”™è¯¯': str(exc),
            })

    # ç”Ÿæˆæ±‡æ€»è¾“å‡º
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    base_name = f"å®æ³¢ä¸–è´¸æ‰¹é‡æ±‡æ€»_{timestamp}"

    # æ€»è¡¨ï¼šåˆå¹¶æ‰€æœ‰äº‹ä»¶
    if all_events:
        all_df = pd.concat(all_events, ignore_index=True)
        combined_csv = os.path.join(output_dir, f"{base_name}_äº‹ä»¶æ˜ç»†.csv")
        all_df.to_csv(combined_csv, index=False, encoding='utf-8-sig')
        print(f"âœ… æ‰¹é‡äº‹ä»¶æ˜ç»†å·²ä¿å­˜: {combined_csv}")

        # ç»Ÿè®¡ï¼šæ•´ä½“ç±»å‹ç»Ÿè®¡/äº‹ä»¶ç»Ÿè®¡/å„ç‚‰ç»Ÿè®¡
        overall_type = all_df['é¢„è­¦/æŠ¥è­¦ç±»å‹'].value_counts().rename('æ•°é‡')
        overall_event = all_df['é¢„è­¦/æŠ¥è­¦äº‹ä»¶'].value_counts().rename('æ•°é‡')
        overall_furnace = all_df['ç‚‰å·'].value_counts().sort_index().rename('æ•°é‡')

        # è¾“å‡ºåˆ°ä¸€ä¸ªExcelä¸­å¤šsheet
        combined_xlsx = os.path.join(output_dir, f"{base_name}_ç»Ÿè®¡.xlsx")
        with pd.ExcelWriter(combined_xlsx, engine='openpyxl') as writer:
            all_df.to_excel(writer, sheet_name='äº‹ä»¶æ˜ç»†', index=False)
            overall_type.to_frame().to_excel(writer, sheet_name='ç±»å‹ç»Ÿè®¡')
            overall_event.to_frame().to_excel(writer, sheet_name='äº‹ä»¶ç»Ÿè®¡')
            overall_furnace.to_frame().to_excel(writer, sheet_name='å„ç‚‰ç»Ÿè®¡')

        print(f"âœ… æ‰¹é‡ç»Ÿè®¡Excelå·²ä¿å­˜: {combined_xlsx}")

    # æ–‡ä»¶çº§ç®€è¡¨
    if file_level_summary:
        summary_df = pd.DataFrame(file_level_summary)
        summary_csv = os.path.join(output_dir, f"{base_name}_å„æ–‡ä»¶æ±‡æ€».csv")
        summary_df.to_csv(summary_csv, index=False, encoding='utf-8-sig')
        print(f"âœ… å„æ–‡ä»¶æ±‡æ€»å·²ä¿å­˜: {summary_csv}")


def main():
    DEFAULT_INPUT_DIR = os.path.join('å®å¾·ä¸–è´¸')
    DEFAULT_OUTPUT_DIR = os.path.join('å®å¾·ä¸–è´¸', 'é¢„è­¦æ–‡ä»¶è¾“å‡º')

    if len(sys.argv) >= 2:
        input_dir = sys.argv[1]
        output_dir = sys.argv[2] if len(sys.argv) > 2 else DEFAULT_OUTPUT_DIR
    else:
        print("ğŸš€ æ‰¹é‡å¤„ç†æ¨¡å¼ï¼ˆä½¿ç”¨é»˜è®¤ç›®å½•ï¼‰")
        print("ğŸ’¡ ç”¨æ³•: python å®å¾·ä¸–è´¸/batch_process.py <è¾“å…¥ç›®å½•> [è¾“å‡ºç›®å½•]")
        input_dir = DEFAULT_INPUT_DIR
        output_dir = DEFAULT_OUTPUT_DIR
        print(f"ğŸ“ è¾“å…¥ç›®å½•: {input_dir}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")

    process_directory(input_dir, output_dir)


if __name__ == '__main__':
    main()


