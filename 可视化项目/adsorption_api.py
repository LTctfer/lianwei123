#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŠ½å–å¼å¸é™„æ›²çº¿é¢„è­¦ç³»ç»ŸHTTPæ¥å£
è°ƒç”¨ç°æœ‰çš„Adsorption_isotherm.pyç®—æ³•å¤„ç†æ•°æ®
"""

from flask import Flask, request, jsonify, Response
import pandas as pd
import numpy as np
from datetime import datetime
import tempfile
import os
import sys
import json

# å¯¼å…¥ç°æœ‰çš„ç®—æ³•
from Adsorption_isotherm import AdsorptionCurveProcessor

app = Flask(__name__)

# è®¾ç½®JSONç¼–ç ï¼Œç¡®ä¿ä¸­æ–‡æ­£ç¡®æ˜¾ç¤º
app.config['JSON_AS_ASCII'] = False
app.config['JSONIFY_PRETTYPRINT_REGULAR'] = True

# è®¾ç½®é»˜è®¤ç¼–ç 
import locale
try:
    locale.setlocale(locale.LC_ALL, 'zh_CN.UTF-8')
except:
    try:
        locale.setlocale(locale.LC_ALL, 'Chinese_China.65001')  # Windowsä¸­æ–‡UTF-8
    except:
        pass

class AdsorptionAPIWrapper:
    """å¸é™„ç®—æ³•APIåŒ…è£…å™¨"""
    
    def __init__(self):
        self.processor = None
        # ä¼šè¯ç®¡ç†ï¼šè®°å½•æ¯ä¸ªä¼šè¯çš„ç´¯è®¡æ—¶é—´åç§»
        self.sessions = {}  # session_id -> {"last_cumulative_time": float, "data_points": list}
    
    def process_json_data(self, json_data: list, session_id: str = None) -> dict:
        """å¤„ç†JSONæ•°æ®å¹¶è°ƒç”¨ç°æœ‰ç®—æ³•ï¼Œæ”¯æŒç´¯åŠ æ¨¡å¼"""
        try:
            # 1. éªŒè¯æ•°æ®æ ¼å¼
            if not isinstance(json_data, list) or len(json_data) == 0:
                return {"status": "failure", "error": "æ•°æ®æ ¼å¼é”™è¯¯æˆ–ä¸ºç©º"}
            
            # 2. è½¬æ¢JSONåˆ°DataFrame
            df = pd.DataFrame(json_data)
            
            # 3. éªŒè¯å¿…è¦å­—æ®µ
            required_fields = ['gVocs', 'inVoc', 'gWindspeed', 'access', 'createTime']
            missing_fields = [field for field in required_fields if field not in df.columns]
            if missing_fields:
                return {"status": "failure", "error": f"ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}"}
            
            # 4. æ•°æ®æ˜ å°„å’Œè½¬æ¢
            # å°†JSONå­—æ®µæ˜ å°„åˆ°ç®—æ³•æœŸæœ›çš„CSVåˆ—å
            df_mapped = pd.DataFrame()
            df_mapped['å‡ºå£voc'] = df['gVocs']
            df_mapped['è¿›å£voc'] = df['inVoc'] 
            df_mapped['é£ç®¡å†…é£é€Ÿå€¼'] = df['gWindspeed']
            df_mapped['è¿›å£0å‡ºå£1'] = df['access']
            df_mapped['åˆ›å»ºæ—¶é—´'] = pd.to_datetime(df['createTime'])
            
            # æ·»åŠ é£é‡å­—æ®µï¼ˆç®—æ³•ä¸­éœ€è¦ï¼Œè®¾ç½®é»˜è®¤å€¼ä¸º1.0ï¼Œé¿å…è¢«è¿‡æ»¤æ‰ï¼‰
            df_mapped['é£é‡'] = 1.0
            
            # 5. åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„ï¼ˆç®—æ³•éœ€è¦ï¼‰
            self._ensure_directories()
            
            # 6. ä¿å­˜ä¸ºä¸´æ—¶CSVæ–‡ä»¶
            temp_csv = tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8-sig')
            df_mapped.to_csv(temp_csv.name, index=False)
            temp_csv.close()
            
            # 7. åˆ›å»ºè‡ªå®šä¹‰çš„ç®—æ³•å¤„ç†å™¨ï¼Œç¦ç”¨æ–‡ä»¶ä¿å­˜åŠŸèƒ½
            processor = self._create_api_processor(temp_csv.name)
            
            # 8. ä½¿ç”¨APIä¸“ç”¨å¤„ç†æ–¹æ³•
            if not processor.api_process_and_visualize():
                os.unlink(temp_csv.name)
                return {"status": "failure", "error": "æ•°æ®å¤„ç†å¤±è´¥"}
            
            # 9. æå–ç»“æœï¼ˆæ”¯æŒç´¯åŠ æ¨¡å¼ï¼‰
            result = self._extract_visualization_data(processor, processor.efficiency_data, session_id)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(temp_csv.name)
            
            # æ·»åŠ æˆåŠŸçŠ¶æ€
            result["status"] = "success"
            return result
            
        except Exception as e:
            return {"status": "yichang", "error": f"å¤„ç†å¤±è´¥: {str(e)}"}

    def _ensure_directories(self):
        """ç¡®ä¿ç®—æ³•éœ€è¦çš„ç›®å½•ç»“æ„å­˜åœ¨"""
        try:
            directories = [
                "å¯è§†åŒ–é¡¹ç›®/æ¸…æ´—åæ•°æ®",
                "å¯è§†åŒ–é¡¹ç›®/å¯è§†åŒ–å›¾åƒ"
            ]
            for directory in directories:
                os.makedirs(directory, exist_ok=True)
        except Exception as e:
            print(f"åˆ›å»ºç›®å½•è­¦å‘Š: {e}")

    def _create_api_processor(self, temp_csv_path: str):
        """åˆ›å»ºAPIä¸“ç”¨çš„ç®—æ³•å¤„ç†å™¨ï¼Œé‡å†™ä¿å­˜æ–¹æ³•é¿å…æ–‡ä»¶æ“ä½œé”™è¯¯"""
        from Adsorption_isotherm import AdsorptionCurveProcessor
        
        # åˆ›å»ºå¤„ç†å™¨å®ä¾‹
        processor = AdsorptionCurveProcessor(temp_csv_path)
        
        # é‡å†™å¯èƒ½å¯¼è‡´æ–‡ä»¶æ“ä½œé”™è¯¯çš„æ–¹æ³•
        def dummy_save_method(*args, **kwargs):
            """ç©ºçš„ä¿å­˜æ–¹æ³•ï¼Œé¿å…æ–‡ä»¶æ“ä½œé”™è¯¯"""
            pass
        
        def dummy_makedirs(*args, **kwargs):
            """ç©ºçš„ç›®å½•åˆ›å»ºæ–¹æ³•"""
            pass
        
        # é‡å†™ä¿å­˜ç›¸å…³çš„æ–¹æ³•
        if hasattr(processor, '_save_cleaned_data'):
            processor._save_cleaned_data = dummy_save_method
        if hasattr(processor, '_save_warning_report'):
            processor._save_warning_report = dummy_save_method
        
        # é‡å†™process_and_visualizeæ–¹æ³•ï¼Œé¿å…æ–‡ä»¶ä¿å­˜æ“ä½œ
        original_process_and_visualize = processor.process_and_visualize
        def api_process_and_visualize():
            """APIä¸“ç”¨çš„å¤„ç†æ–¹æ³•ï¼Œä¸ä¿å­˜æ–‡ä»¶"""
            # ç›´æ¥æ‰§è¡Œæ•°æ®å¤„ç†é€»è¾‘ï¼Œè·³è¿‡æ–‡ä»¶ä¿å­˜
            try:
                print("=== APIæ¨¡å¼ï¼šæŠ½å–å¼å¸é™„æ›²çº¿æ•°æ®å¤„ç† ===")
                
                # 1. åŠ è½½æ•°æ®
                if not processor.load_data():
                    return False
                
                # 2. åŸºç¡€æ•°æ®æ¸…æ´—  
                basic_cleaned = processor.basic_data_cleaning(processor.raw_data)
                if len(basic_cleaned) == 0:
                    return False
                
                # 3. é«˜çº§ç­›é€‰
                processor.cleaned_data_ks = processor.ks_test_cleaning(basic_cleaned)
                processor.cleaned_data_boxplot = processor.boxplot_cleaning(basic_cleaned)
                
                # é€‰æ‹©æ•°æ®é‡æ›´å°‘çš„ç­›é€‰ç»“æœ
                ks_count = len(processor.cleaned_data_ks) if processor.cleaned_data_ks is not None else 0
                boxplot_count = len(processor.cleaned_data_boxplot) if processor.cleaned_data_boxplot is not None else 0
                
                if ks_count > 0 and boxplot_count > 0:
                    if ks_count <= boxplot_count:
                        processor.final_cleaned_data = processor.cleaned_data_ks
                        processor.selected_method = "K-Sæ£€éªŒ"
                    else:
                        processor.final_cleaned_data = processor.cleaned_data_boxplot
                        processor.selected_method = "ç®±å‹å›¾"
                elif ks_count > 0:
                    processor.final_cleaned_data = processor.cleaned_data_ks
                    processor.selected_method = "K-Sæ£€éªŒ"
                elif boxplot_count > 0:
                    processor.final_cleaned_data = processor.cleaned_data_boxplot
                    processor.selected_method = "ç®±å‹å›¾"
                else:
                    return False
                
                # 4. è®¡ç®—æ•ˆç‡æ•°æ®
                processor.efficiency_data = processor.calculate_efficiency_with_two_rules(
                    processor.final_cleaned_data, processor.selected_method)
                
                if processor.efficiency_data is None or processor.efficiency_data.empty:
                    return False
                
                # 5. é¢„è­¦ç³»ç»Ÿåˆ†æï¼ˆä¸ä¿å­˜æ–‡ä»¶ï¼‰
                try:
                    processor.analyze_warning_system_with_final_data()
                except Exception as e:
                    print(f"é¢„è­¦åˆ†æè­¦å‘Š: {e}")
                
                return True
                
            except Exception as e:
                print(f"APIå¤„ç†è­¦å‘Š: {e}")
                return False
        
        processor.api_process_and_visualize = api_process_and_visualize
        
        return processor

    def _extract_visualization_data(self, processor: AdsorptionCurveProcessor, efficiency_data: pd.DataFrame, session_id: str = None) -> dict:
        """ä»ç®—æ³•ç»“æœä¸­æå–å¯è§†åŒ–æ•°æ®ï¼Œæ”¯æŒç´¯åŠ æ¨¡å¼"""
        try:
            # è·å–ä¼šè¯çš„æ—¶é—´åç§»
            time_offset = 0.0
            if session_id:
                if session_id not in self.sessions:
                    # åˆå§‹åŒ–ä¼šè¯
                    self.sessions[session_id] = {
                        "last_cumulative_time": 0.0,
                        "data_points": []
                    }
                else:
                    # è·å–ä¸Šæ¬¡çš„æœ€åç´¯è®¡æ—¶é—´ä½œä¸ºåç§»
                    time_offset = self.sessions[session_id]["last_cumulative_time"]
            
            # æå–æ•°æ®ç‚¹
            data_points = []
            max_time_in_batch = 0.0  # è®°å½•æœ¬æ‰¹æ¬¡çš„æœ€å¤§æ—¶é—´
            
            for idx, row in efficiency_data.iterrows():
                # è·å–å½“å‰æ‰¹æ¬¡çš„æ—¶é—´ï¼ˆå°æ—¶ï¼‰- ç®—æ³•ä¸­å·²ç»è®¡ç®—å¥½çš„æ—¶é—´åæ ‡
                current_time_hours = float(row['æ—¶é—´åæ ‡'])  # ç®—æ³•ä¸­æ—¶é—´åæ ‡å·²ç»æ˜¯å°æ—¶å•ä½
                
                # åº”ç”¨æ—¶é—´åç§»ï¼Œå®ç°ç´¯åŠ 
                cumulative_time_hours = current_time_hours + time_offset
                
                # æ›´æ–°æœ¬æ‰¹æ¬¡æœ€å¤§æ—¶é—´
                max_time_in_batch = max(max_time_in_batch, cumulative_time_hours)
                
                # è·å–ç©¿é€ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰
                breakthrough_ratio = float(row['ç©¿é€ç‡']) * 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
                
                # è·å–å¤„ç†æ•ˆç‡
                efficiency = float(row['å¤„ç†æ•ˆç‡'])
                
                # ç”Ÿæˆæ—¶é—´æ®µæ ‡è¯†
                if 'window_start' in row and 'window_end' in row:
                    # ä½¿ç”¨ç®—æ³•ä¸­çš„æ—¶é—´çª—å£æ ¼å¼
                    start_time = pd.to_datetime(row['window_start'])
                    end_time = pd.to_datetime(row['window_end'])
                    time_segment = f"{start_time.strftime('%m-%d %H:%M')}-{end_time.strftime('%H:%M')}"
                else:
                    # æ ¹æ®è®¡ç®—è§„åˆ™ç”Ÿæˆæ—¶é—´æ®µæ ‡è¯†
                    if 'è®¡ç®—è§„åˆ™' in row:
                        rule = row['è®¡ç®—è§„åˆ™']
                        if rule == 'è§„åˆ™1-é£é€Ÿæ®µ' and 'é£é€Ÿæ®µ' in row:
                            time_segment = f"é£é€Ÿæ®µ{int(row['é£é€Ÿæ®µ'])}"
                        elif rule == 'è§„åˆ™2-æ‹¼æ¥æ®µ' and 'æ‹¼æ¥æ—¶é—´æ®µ' in row:
                            time_segment = f"æ‹¼æ¥æ®µ{int(row['æ‹¼æ¥æ—¶é—´æ®µ'])}"
                        else:
                            time_segment = f"æ—¶é—´æ®µ{idx+1}"
                    else:
                        time_segment = f"æ—¶é—´æ®µ{idx+1}"
                
                # æŒ‰ç…§ç®—æ³•å†…çš„æ ‡ç­¾æ ¼å¼ï¼šæ—¶é—´æ®µã€ç´¯è®¡æ—¶é•¿å’Œç©¿é€ç‡ï¼ˆä½¿ç”¨ç´¯åŠ åçš„æ—¶é—´ï¼‰
                label = f"æ—¶é—´æ®µ: {time_segment}\nç´¯ç§¯æ—¶é•¿: {cumulative_time_hours:.2f}å°æ—¶\nç©¿é€ç‡: {breakthrough_ratio:.1f}%"
                
                # æ•°å€¼æ ¼å¼åŒ–ï¼šä¿ç•™2ä½å°æ•°ï¼Œæ¥è¿‘0åˆ™è¿”å›0
                def format_number(value):
                    """æ ¼å¼åŒ–æ•°å€¼ï¼Œä¿ç•™2ä½å°æ•°ï¼Œæ¥è¿‘0åˆ™è¿”å›0"""
                    if abs(value) < 0.01:  # å°äº0.01è§†ä¸ºæ¥è¿‘0
                        return 0.0
                    return round(value, 2)
                
                data_points.append({
                    "x": format_number(cumulative_time_hours),  # Xè½´ï¼šç´¯è®¡è¿è¡Œæ—¶é—´ï¼ˆå°æ—¶ï¼‰- å·²ç´¯åŠ 
                    "y": format_number(breakthrough_ratio),  # Yè½´ï¼šç©¿é€ç‡ï¼ˆ%ï¼‰
                    "label": label,  # æŒ‰ç®—æ³•æ ¼å¼çš„æ ‡ç­¾
                    "time_segment": time_segment,
                    "cumulative_hours": format_number(cumulative_time_hours),  # ç´¯åŠ åçš„æ—¶é—´
                    "original_hours": format_number(current_time_hours),  # æœ¬æ‰¹æ¬¡åŸå§‹æ—¶é—´
                    "time_offset": format_number(time_offset),  # æ—¶é—´åç§»é‡
                    "breakthrough_percent": format_number(breakthrough_ratio),
                    "efficiency": format_number(efficiency),
                    "inlet_concentration": format_number(float(row.get('è¿›å£æµ“åº¦', 0))),
                    "outlet_concentration": format_number(float(row.get('å‡ºå£æµ“åº¦', 0))),
                    "calculation_rule": row.get('è®¡ç®—è§„åˆ™', ''),
                    "data_count": int(row.get('æ•°æ®ç‚¹æ•°', 1))
                })
            
            # æ›´æ–°ä¼šè¯çŠ¶æ€
            if session_id and max_time_in_batch > 0:
                # ä¿å­˜æœ¬æ‰¹æ¬¡çš„æ•°æ®ç‚¹åˆ°ä¼šè¯ä¸­
                self.sessions[session_id]["data_points"].extend(data_points)
                # æ›´æ–°æœ€åç´¯è®¡æ—¶é—´
                self.sessions[session_id]["last_cumulative_time"] = max_time_in_batch
            
            # æå–é¢„è­¦ç‚¹ï¼ˆåº”ç”¨æ—¶é—´åç§»ï¼‰
            warning_points = self._extract_warning_points(processor, time_offset)
            
            # æ„å»ºè¿”å›ç»“æœ
            result = {
                "data_points": data_points,
                "warning_points": warning_points,
                "total_points": len(data_points),
                "session_info": {}
            }
            
            # å¦‚æœæœ‰ä¼šè¯ä¿¡æ¯ï¼Œæ·»åŠ åˆ°ç»“æœä¸­
            if session_id:
                all_data_points = self.sessions[session_id]["data_points"]
                result["session_info"] = {
                    "session_id": session_id,
                    "current_batch_points": len(data_points),
                    "total_accumulated_points": len(all_data_points),
                    "last_cumulative_time": self.sessions[session_id]["last_cumulative_time"],
                    "time_offset_applied": time_offset,
                    "all_accumulated_points": all_data_points  # è¿”å›æ‰€æœ‰ç´¯ç§¯çš„æ•°æ®ç‚¹
                }
            
            return result
            
        except Exception as e:
            return {"error": f"æ•°æ®æå–å¤±è´¥: {str(e)}"}
    
    def _extract_warning_points(self, processor: AdsorptionCurveProcessor, time_offset: float = 0.0) -> list:
        """æå–é¢„è­¦ç‚¹ï¼ˆäº”è§’æ˜Ÿæ ‡æ³¨çš„ç‚¹ï¼‰ï¼Œæ”¯æŒæ—¶é—´åç§»"""
        warning_points = []
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰é¢„è­¦æ¨¡å‹å¹¶ä¸”å·²æ‹Ÿåˆ
            if hasattr(processor, 'warning_model') and processor.warning_model.fitted:
                model = processor.warning_model
                
                # æ•°å€¼æ ¼å¼åŒ–å‡½æ•°
                def format_number(value):
                    """æ ¼å¼åŒ–æ•°å€¼ï¼Œä¿ç•™2ä½å°æ•°ï¼Œæ¥è¿‘0åˆ™è¿”å›0"""
                    if abs(value) < 0.01:  # å°äº0.01è§†ä¸ºæ¥è¿‘0
                        return 0.0
                    return round(value, 2)
                
                # è·å–é¢„è­¦æ—¶é—´ç‚¹ï¼ˆå¯¹åº”å›¾åƒä¸­çš„æ©™è‰²äº”è§’æ˜Ÿæ ‡æ³¨ï¼‰
                if hasattr(model, 'warning_time') and model.warning_time is not None:
                    # è®¡ç®—é¢„è­¦æ—¶é—´ç‚¹çš„ç©¿é€ç‡ï¼ˆä½¿ç”¨Logisticæ¨¡å‹é¢„æµ‹ï¼‰
                    warning_time_seconds = model.warning_time
                    warning_breakthrough = model.predict_breakthrough(np.array([warning_time_seconds]))[0] * 100
                    warning_time_hours = warning_time_seconds / 3600 + time_offset  # åº”ç”¨æ—¶é—´åç§»
                    
                    warning_points.append({
                        "x": format_number(warning_time_hours),  # Xè½´ï¼šé¢„è­¦æ—¶é—´ï¼ˆå°æ—¶ï¼‰- å·²ç´¯åŠ 
                        "y": format_number(warning_breakthrough),  # Yè½´ï¼šé¢„è­¦ç‚¹ç©¿é€ç‡ï¼ˆ%ï¼‰
                        "type": "warning_star",
                        "color": "orange",
                        "description": f"é¢„è­¦ç‚¹(ç©¿é€ç‡:{format_number(warning_breakthrough)}%)",
                        "original_time": format_number(warning_time_seconds / 3600),  # åŸå§‹æ—¶é—´
                        "time_offset": format_number(time_offset)  # æ—¶é—´åç§»
                    })
                
                # è·å–é¢„æµ‹é¥±å’Œæ—¶é—´ç‚¹ï¼ˆå¯¹åº”å›¾åƒä¸­çš„çº¢è‰²äº”è§’æ˜Ÿæ ‡æ³¨ï¼‰
                if hasattr(model, 'predicted_saturation_time') and model.predicted_saturation_time is not None:
                    saturation_time_seconds = model.predicted_saturation_time
                    saturation_breakthrough = model.predict_breakthrough(np.array([saturation_time_seconds]))[0] * 100
                    saturation_time_hours = saturation_time_seconds / 3600 + time_offset  # åº”ç”¨æ—¶é—´åç§»
                    
                    warning_points.append({
                        "x": format_number(saturation_time_hours),  # å·²ç´¯åŠ 
                        "y": format_number(saturation_breakthrough),
                        "type": "saturation_star",
                        "color": "red",
                        "description": f"é¢„æµ‹é¥±å’Œç‚¹(ç©¿é€ç‡:{format_number(saturation_breakthrough)}%)",
                        "original_time": format_number(saturation_time_seconds / 3600),
                        "time_offset": format_number(time_offset)
                    })
                
                # è·å–ç©¿é€èµ·å§‹æ—¶é—´ç‚¹ï¼ˆå¯¹åº”å›¾åƒä¸­çš„ç»¿è‰²å‚ç›´çº¿ï¼‰
                if hasattr(model, 'breakthrough_start_time') and model.breakthrough_start_time is not None:
                    start_time_seconds = model.breakthrough_start_time
                    start_breakthrough = model.predict_breakthrough(np.array([start_time_seconds]))[0] * 100
                    start_time_hours = start_time_seconds / 3600 + time_offset  # åº”ç”¨æ—¶é—´åç§»
                    
                    warning_points.append({
                        "x": format_number(start_time_hours),  # å·²ç´¯åŠ 
                        "y": format_number(start_breakthrough),
                        "type": "breakthrough_start",
                        "color": "green",
                        "description": f"ç©¿é€èµ·å§‹ç‚¹(ç©¿é€ç‡:{format_number(start_breakthrough)}%)",
                        "original_time": format_number(start_time_seconds / 3600),
                        "time_offset": format_number(time_offset)
                    })
        
        except Exception as e:
            print(f"é¢„è­¦ç‚¹æå–è­¦å‘Š: {e}")
        
        return warning_points

    def reset_session(self, session_id: str) -> bool:
        """é‡ç½®æŒ‡å®šä¼šè¯"""
        if session_id in self.sessions:
            del self.sessions[session_id]
            return True
        return False

    def get_session_info(self, session_id: str) -> dict:
        """è·å–ä¼šè¯ä¿¡æ¯"""
        if session_id in self.sessions:
            session_data = self.sessions[session_id]
            return {
                "session_id": session_id,
                "exists": True,
                "total_points": len(session_data["data_points"]),
                "last_cumulative_time": session_data["last_cumulative_time"],
                "data_points": session_data["data_points"]
            }
        else:
            return {
                "session_id": session_id,
                "exists": False,
                "total_points": 0,
                "last_cumulative_time": 0.0,
                "data_points": []
            }

    def list_all_sessions(self) -> dict:
        """åˆ—å‡ºæ‰€æœ‰ä¼šè¯"""
        sessions_info = {}
        for session_id, session_data in self.sessions.items():
            sessions_info[session_id] = {
                "total_points": len(session_data["data_points"]),
                "last_cumulative_time": session_data["last_cumulative_time"]
            }
        return {
            "total_sessions": len(self.sessions),
            "sessions": sessions_info
        }

def create_json_response(data, status_code=200):
    """åˆ›å»ºUTF-8ç¼–ç çš„JSONå“åº”ï¼Œç¡®ä¿ä¸­æ–‡æ­£ç¡®æ˜¾ç¤º"""
    try:
        # ä½¿ç”¨json.dumpsç¡®ä¿ä¸­æ–‡æ­£ç¡®ç¼–ç 
        json_str = json.dumps(data, ensure_ascii=False, indent=2)
        
        # åˆ›å»ºå“åº”å¯¹è±¡
        response = Response(
            json_str,
            status=status_code,
            mimetype='application/json; charset=utf-8'
        )
        
        # è®¾ç½®å“åº”å¤´
        response.headers['Content-Type'] = 'application/json; charset=utf-8'
        response.headers['Cache-Control'] = 'no-cache'
        
        return response
    except Exception as e:
        # å¦‚æœå‡ºé”™ï¼Œè¿”å›åŸºæœ¬çš„é”™è¯¯å“åº”
        error_data = {"error": f"å“åº”ç¼–ç é”™è¯¯: {str(e)}"}
        error_json = json.dumps(error_data, ensure_ascii=False)
        return Response(
            error_json,
            status=500,
            mimetype='application/json; charset=utf-8'
        )

# åˆ›å»ºAPIåŒ…è£…å™¨å®ä¾‹
api_wrapper = AdsorptionAPIWrapper()

@app.route('/api/extraction-adsorption-curve/process', methods=['POST'])
def process_extraction_adsorption_curve():
    """æŠ½å–å¼å¸é™„æ›²çº¿é¢„è­¦ç³»ç»ŸAPIæ¥å£"""
    try:
        # è·å–JSONæ•°æ®
        request_data = request.get_json(force=True)
        
        if not request_data:
            return create_json_response({"error": "æœªæä¾›JSONæ•°æ®"}, 400)
        
        # æå–ä¼šè¯IDå’Œæ•°æ®
        session_id = request_data.get('session_id', None)
        json_data = request_data.get('data', request_data)
        
        # å¦‚æœæ•´ä¸ªè¯·æ±‚å°±æ˜¯æ•°æ®æ•°ç»„ï¼Œåˆ™ä½¿ç”¨æ•´ä¸ªè¯·æ±‚ä½œä¸ºæ•°æ®
        if isinstance(request_data, list):
            json_data = request_data
            session_id = None
        
        # å¤„ç†æ•°æ®
        result = api_wrapper.process_json_data(json_data, session_id)
        
        # æ ¹æ®çŠ¶æ€è¿”å›ä¸åŒçš„HTTPçŠ¶æ€ç 
        if result.get("status") == "success":
            return create_json_response(result, 200)
        elif result.get("status") == "yichang":
            return create_json_response(result, 500)
        else:  # failure
            return create_json_response(result, 400)
        
    except Exception as e:
        error_result = {"error": f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}"}
        return create_json_response(error_result, 500)

@app.route('/api/extraction-adsorption-curve/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    health_data = {
        "status": "healthy",
        "service": "extraction_adsorption_curve_warning_system",
        "version": "1.0.0",
        "encoding": "UTF-8"
    }
    return create_json_response(health_data)

@app.route('/api/extraction-adsorption-curve/info', methods=['GET'])
def api_info():
    """APIä¿¡æ¯æ¥å£"""
    info_data = {
        "api_name": "æŠ½å–å¼å¸é™„æ›²çº¿é¢„è­¦ç³»ç»Ÿ",
        "version": "1.0.0",
        "description": "åŸºäºç°æœ‰Adsorption_isotherm.pyç®—æ³•çš„HTTPæ¥å£ï¼Œå¤„ç†VOCç›‘æµ‹æ•°æ®å¹¶è¿”å›å¯è§†åŒ–åæ ‡ç‚¹å’Œé¢„è­¦ä¿¡æ¯",
        "encoding": "UTF-8",
        "endpoints": {
            "/api/extraction-adsorption-curve/process": {
                "method": "POST",
                "description": "å¤„ç†æŠ½å–å¼å¸é™„æ›²çº¿æ•°æ®ï¼Œè¿”å›æ•°æ®ç‚¹åæ ‡å’Œé¢„è­¦ç‚¹åæ ‡ï¼Œæ”¯æŒç´¯åŠ æ¨¡å¼",
                "input_format": {
                    "session_id": "å¯é€‰ï¼Œä¼šè¯IDï¼Œç”¨äºç´¯åŠ æ•°æ®å¤„ç†",
                    "data": "æ•°æ®æ•°ç»„ï¼Œæˆ–ç›´æ¥å‘é€æ•°ç»„æ ¼å¼",
                    "gVocs": "å‡ºå£VOCæµ“åº¦ -> å‡ºå£vocåˆ—",
                    "inVoc": "è¿›å£VOCæµ“åº¦ -> è¿›å£vocåˆ—", 
                    "gWindspeed": "é£ç®¡å†…é£é€Ÿ -> é£ç®¡å†…é£é€Ÿå€¼åˆ—",
                    "access": "è¿›å£(0)æˆ–å‡ºå£(1)æˆ–åŒæ—¶(2) -> è¿›å£0å‡ºå£1åˆ—",
                    "createTime": "åˆ›å»ºæ—¶é—´ -> åˆ›å»ºæ—¶é—´åˆ—",
                    "é£é‡": "è‡ªåŠ¨è®¾ç½®ä¸º1.0ï¼ˆç®—æ³•å†…éƒ¨éœ€è¦ï¼Œæ— éœ€ç”¨æˆ·æä¾›ï¼‰"
                },
                "output_format": {
                    "data_points": "æ•°æ®ç‚¹æ•°ç»„ï¼ŒåŒ…å«x(ç´¯è®¡æ—¶é—´)ã€y(ç©¿é€ç‡)ã€label(æ ‡ç­¾)",
                    "warning_points": "é¢„è­¦ç‚¹æ•°ç»„ï¼ŒåŒ…å«x(ç´¯è®¡æ—¶é—´)ã€y(ç©¿é€ç‡)ï¼Œå¯¹åº”å›¾åƒä¸­çš„äº”è§’æ˜Ÿæ ‡æ³¨ç‚¹",
                    "session_info": "ä¼šè¯ä¿¡æ¯ï¼ŒåŒ…å«ç´¯è®¡æ•°æ®ç‚¹å’Œæ—¶é—´åç§»ä¿¡æ¯"
                },
                "cumulative_mode": {
                    "description": "ç´¯åŠ æ¨¡å¼è¯´æ˜ï¼šæä¾›session_idæ—¶ï¼Œæ¯æ¬¡å¤„ç†çš„æ—¶é—´åæ ‡ä¼šåœ¨ä¸Šæ¬¡çš„æœ€åæ—¶é—´åŸºç¡€ä¸Šç´¯åŠ ",
                    "example": "ç¬¬ä¸€æ¬¡è¿”å›x=[1,3,4,5]ï¼Œç¬¬äºŒæ¬¡å¤„ç†ä¼šåœ¨5çš„åŸºç¡€ä¸Šç´¯åŠ ï¼Œè¿”å›x=[6,8,9,10]"
                }
            },
            "/api/extraction-adsorption-curve/session/<session_id>": {
                "method": "GET",
                "description": "è·å–æŒ‡å®šä¼šè¯çš„ç´¯ç§¯æ•°æ®ä¿¡æ¯"
            },
            "/api/extraction-adsorption-curve/session/<session_id>": {
                "method": "DELETE", 
                "description": "é‡ç½®æŒ‡å®šä¼šè¯ï¼Œæ¸…é™¤ç´¯ç§¯æ•°æ®"
            },
            "/api/extraction-adsorption-curve/sessions": {
                "method": "GET",
                "description": "åˆ—å‡ºæ‰€æœ‰æ´»è·ƒä¼šè¯"
            },
            "/api/extraction-adsorption-curve/health": {
                "method": "GET",
                "description": "å¥åº·æ£€æŸ¥"
            },
            "/api/extraction-adsorption-curve/info": {
                "method": "GET", 
                "description": "APIä¿¡æ¯"
            }
        }
    }
    return create_json_response(info_data)

@app.route('/api/extraction-adsorption-curve/session/<session_id>', methods=['GET'])
def get_session_info(session_id):
    """è·å–æŒ‡å®šä¼šè¯ä¿¡æ¯"""
    try:
        session_info = api_wrapper.get_session_info(session_id)
        return create_json_response(session_info)
    except Exception as e:
        error_result = {"error": f"è·å–ä¼šè¯ä¿¡æ¯å¤±è´¥: {str(e)}"}
        return create_json_response(error_result, 500)

@app.route('/api/extraction-adsorption-curve/session/<session_id>', methods=['DELETE'])
def reset_session(session_id):
    """é‡ç½®æŒ‡å®šä¼šè¯"""
    try:
        success = api_wrapper.reset_session(session_id)
        if success:
            return create_json_response({"message": f"ä¼šè¯ {session_id} å·²é‡ç½®", "success": True})
        else:
            return create_json_response({"message": f"ä¼šè¯ {session_id} ä¸å­˜åœ¨", "success": False}, 404)
    except Exception as e:
        error_result = {"error": f"é‡ç½®ä¼šè¯å¤±è´¥: {str(e)}"}
        return create_json_response(error_result, 500)

@app.route('/api/extraction-adsorption-curve/sessions', methods=['GET'])
def list_sessions():
    """åˆ—å‡ºæ‰€æœ‰ä¼šè¯"""
    try:
        sessions_info = api_wrapper.list_all_sessions()
        return create_json_response(sessions_info)
    except Exception as e:
        error_result = {"error": f"è·å–ä¼šè¯åˆ—è¡¨å¤±è´¥: {str(e)}"}
        return create_json_response(error_result, 500)

if __name__ == '__main__':
    print("å¯åŠ¨æŠ½å–å¼å¸é™„æ›²çº¿é¢„è­¦ç³»ç»Ÿï¼ˆæ”¯æŒç´¯åŠ æ•°æ®å¤„ç†ï¼‰...")
    print("=" * 60)
    print("ğŸ“– APIç«¯ç‚¹:")
    print("  APIæ–‡æ¡£: http://localhost:5000/api/extraction-adsorption-curve/info")
    print("  å¥åº·æ£€æŸ¥: http://localhost:5000/api/extraction-adsorption-curve/health")
    print("  æ•°æ®å¤„ç†: POST http://localhost:5000/api/extraction-adsorption-curve/process")
    print("  ä¼šè¯ç®¡ç†: GET/DELETE http://localhost:5000/api/extraction-adsorption-curve/session/<session_id>")
    print("  ä¼šè¯åˆ—è¡¨: GET http://localhost:5000/api/extraction-adsorption-curve/sessions")
    print("=" * 60)
    print("ğŸ”„ ç´¯åŠ æ¨¡å¼ä½¿ç”¨è¯´æ˜:")
    print("  1. åœ¨è¯·æ±‚ä¸­æ·»åŠ  'session_id' å­—æ®µæ¥å¯ç”¨ç´¯åŠ æ¨¡å¼")
    print("  2. åŒä¸€session_idçš„åç»­è¯·æ±‚ä¼šåœ¨å‰æ¬¡æœ€åæ—¶é—´åŸºç¡€ä¸Šç´¯åŠ ")
    print("  3. ä¾‹å¦‚ç¬¬ä¸€æ¬¡è¿”å›x=[1,3,4,5]ï¼Œç¬¬äºŒæ¬¡ä¼šè¿”å›x=[6,8,9,10]ç­‰")
    print("  4. ä½¿ç”¨DELETEç«¯ç‚¹å¯ä»¥é‡ç½®ä¼šè¯çŠ¶æ€")
    print("=" * 60)
    app.run(debug=True, host='0.0.0.0', port=5000)

