import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, Optional, Tuple, List
import os
import warnings
warnings.filterwarnings('ignore')

# å®æ³¢ä¸–è´¸å­—æ®µæŒ‰ç‚‰å·çš„åˆ—åæ¨¡æ¿ï¼ˆåŒ¹é… 20250101.csv åˆ—åï¼‰
def get_field_mapping_for_furnace(furnace_no: int) -> Dict[str, str]:
    prefix = f"{furnace_no}å·ç‚‰"
    return {
        "upper_temp": f"{prefix}ç‚‰è†›ä¸Šéƒ¨æ¸©åº¦",
        "middle_temp": f"{prefix}ç‚‰è†›ä¸­éƒ¨æ¸©åº¦",
        "bag_pressure": f"{prefix}å¸ƒè¢‹è¿›å‡ºå£å‹å·®",
        "o2": f"{prefix}O2",
        "dust": f"{prefix}ç²‰å°˜",
        "so2": f"{prefix}SO2",
        "nox": f"{prefix}Nox",
        "co": f"{prefix}CO",
        "hcl": f"{prefix}HCL",
        "carbon": f"{prefix}æ´»æ€§ç‚­å–·å°„é‡",
    }

# å»ºå¾·æ•°æ®å­—æ®µæ˜ å°„ (åŸºäºå®é™…CSVæ–‡ä»¶çš„åˆ—å)
JIANDE_FIELD_MAPPING = {
    "furnace_temp_points": [
        "ä¸Šéƒ¨çƒŸæ°”æ¸©åº¦å·¦", "ä¸Šéƒ¨çƒŸæ°”æ¸©åº¦ä¸­", "ä¸Šéƒ¨çƒŸæ°”æ¸©åº¦å³",  # ä¸Šéƒ¨æ–­é¢
        "ä¸­éƒ¨çƒŸæ°”æ¸©åº¦å·¦", "ä¸­éƒ¨çƒŸæ°”æ¸©åº¦ä¸­", "ä¸­éƒ¨çƒŸæ°”æ¸©åº¦å³",  # ä¸­éƒ¨æ–­é¢
        "ä¸‹éƒ¨çƒŸæ°”æ¸©åº¦å·¦", "ä¸‹éƒ¨çƒŸæ°”æ¸©åº¦ä¸­", "ä¸‹éƒ¨çƒŸæ°”æ¸©åº¦å³"   # ä¸‹éƒ¨æ–­é¢
    ],
    "furnace_temp_1": "ä¸Šéƒ¨çƒŸæ°”æ¸©åº¦å·¦",
    "furnace_temp_2": "ä¸Šéƒ¨çƒŸæ°”æ¸©åº¦ä¸­",
    "furnace_temp_3": "ä¸Šéƒ¨çƒŸæ°”æ¸©åº¦å³",
    "furnace_temp_4": "ä¸­éƒ¨çƒŸæ°”æ¸©åº¦å·¦",
    "furnace_temp_5": "ä¸­éƒ¨çƒŸæ°”æ¸©åº¦ä¸­",
    "furnace_temp_6": "ä¸­éƒ¨çƒŸæ°”æ¸©åº¦å³",
    "furnace_temp_7": "ä¸‹éƒ¨çƒŸæ°”æ¸©åº¦å·¦",
    "furnace_temp_8": "ä¸‹éƒ¨çƒŸæ°”æ¸©åº¦ä¸­",
    "furnace_temp_9": "ä¸‹éƒ¨çƒŸæ°”æ¸©åº¦å³",
    "bag_pressure": "é™¤å°˜å™¨å·®å‹",
    "o2": "çƒŸæ°”æ°§é‡",
    "dust": "çƒŸæ°”çƒŸå°˜",
    "so2": "SO2æµ“åº¦",
    "nox": "NOXæµ“åº¦",
    "co": "COæµ“åº¦",
    "hcl": "HCLæµ“åº¦",
}

# é¢„è­¦é˜ˆå€¼é…ç½®ï¼ˆå®æ³¢ä¸–è´¸ï¼‰- åŸºäº1å°æ—¶å‡å€¼
NINGBO_WARNING_THRESHOLDS = {
    "low_furnace_temp": 850,          # ç¬æ—¶ä½ç‚‰æ¸©ç„šçƒ§ï¼ˆ5åˆ†é’Ÿå‡å€¼ï¼‰
    "high_furnace_temp": 1200,        # ç‚‰è†›æ¸©åº¦åé«˜ï¼ˆ1å°æ—¶å‡å€¼ï¼‰  
    "very_high_furnace_temp": 1300,   # ç‚‰è†›æ¸©åº¦è¿‡é«˜ï¼ˆ1å°æ—¶å‡å€¼ï¼‰
    "bag_pressure_high": 2000,        # å¸ƒè¢‹é™¤å°˜å™¨å‹åŠ›æŸå¤±åé«˜ï¼ˆå®æ—¶ï¼‰
    "bag_pressure_low": 500,          # å¸ƒè¢‹é™¤å°˜å™¨å‹åŠ›æŸå¤±åä½ï¼ˆå®æ—¶ï¼‰
    "o2_high": 10,                    # ç„šçƒ§ç‚‰å‡ºå£æ°§å«é‡åé«˜ï¼ˆå®æ—¶ï¼‰
    "o2_low": 6,                      # ç„šçƒ§ç‚‰å‡ºå£æ°§å«é‡åä½ï¼ˆå®æ—¶ï¼‰
    "dust_warning_limit": 30,         # é¢—ç²’ç‰©æµ“åº¦è¾ƒé«˜ï¼ˆ1å°æ—¶å‡å€¼ï¼ŒæŠ˜ç®—åï¼‰
    "nox_warning_limit": 300,         # æ°®æ°§åŒ–ç‰©æµ“åº¦è¾ƒé«˜ï¼ˆ1å°æ—¶å‡å€¼ï¼ŒæŠ˜ç®—åï¼‰
    "so2_warning_limit": 100,         # äºŒæ°§åŒ–ç¡«æµ“åº¦è¾ƒé«˜ï¼ˆ1å°æ—¶å‡å€¼ï¼ŒæŠ˜ç®—åï¼‰
    "hcl_warning_limit": 60,          # æ°¯åŒ–æ°¢æµ“åº¦è¾ƒé«˜ï¼ˆ1å°æ—¶å‡å€¼ï¼ŒæŠ˜ç®—åï¼‰
    "co_warning_limit": 100,          # ä¸€æ°§åŒ–ç¢³æµ“åº¦è¾ƒé«˜ï¼ˆ1å°æ—¶å‡å€¼ï¼ŒæŠ˜ç®—åï¼‰
    "activated_carbon_low": 3.0,      # æ´»æ€§ç‚­æŠ•åŠ é‡ä¸è¶³(kg/hï¼Œå®æ—¶ç›‘æ§)
    "nh3_warning_limit": 8            # æ°¨é€ƒé€¸åé«˜(ppmï¼Œ1å°æ—¶å‡å€¼)
}

# æŠ¥è­¦é˜ˆå€¼é…ç½®ï¼ˆå®æ³¢ä¸–è´¸ï¼‰- åŸºäº24å°æ—¶æ—¥å‡å€¼ï¼ˆæŠ˜ç®—åï¼‰
NINGBO_ALARM_THRESHOLDS = {
    "low_furnace_temp": 850,        # ä½ç‚‰æ¸©ç„šçƒ§æŠ¥è­¦ï¼ˆ5åˆ†é’Ÿå‡å€¼ï¼‰
    "dust_alarm_limit": 20,         # é¢—ç²’ç‰©(PM)æ’æ”¾è¶…æ ‡ï¼ˆ24å°æ—¶æ—¥å‡å€¼ï¼‰
    "nox_alarm_limit": 250,         # æ°®æ°§åŒ–ç‰©(NOx)æ’æ”¾è¶…æ ‡ï¼ˆ24å°æ—¶æ—¥å‡å€¼ï¼‰
    "so2_alarm_limit": 80,          # äºŒæ°§åŒ–ç¡«(SOâ‚‚)æ’æ”¾è¶…æ ‡ï¼ˆ24å°æ—¶æ—¥å‡å€¼ï¼‰
    "hcl_alarm_limit": 50,          # æ°¯åŒ–æ°¢(HCl)æ’æ”¾è¶…æ ‡ï¼ˆ24å°æ—¶æ—¥å‡å€¼ï¼‰
    "co_alarm_limit": 80,           # ä¸€æ°§åŒ–ç¢³(CO)æ’æ”¾è¶…æ ‡ï¼ˆ24å°æ—¶æ—¥å‡å€¼ï¼‰
}

class WasteIncinerationWarningSystemNingbo:
    """åƒåœ¾ç„šçƒ§é¢„è­¦/æŠ¥è­¦ç³»ç»Ÿ - å®æ³¢ä¸–è´¸ (æ”¯æŒ3-6å·ç‚‰)"""

    def __init__(self):
        self.warning_events = []
        self.warning_status = {}
        self.furnace_list = [3, 4, 5, 6]

    def load_data(self, file_path: str) -> pd.DataFrame:
        """åŠ è½½æ•°æ®æ–‡ä»¶ (æ”¯æŒcsvå’Œxlsx)"""
        try:
            if file_path.endswith('.xlsx'):
                df = pd.read_excel(file_path)
            elif file_path.endswith('.csv'):
                df = pd.read_csv(file_path, encoding='utf-8-sig')
            else:
                raise ValueError("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä½¿ç”¨csvæˆ–xlsxæ–‡ä»¶")

            # è½¬æ¢æ—¶é—´åˆ—
            if 'æ•°æ®æ—¶é—´' in df.columns:
                df['æ•°æ®æ—¶é—´'] = pd.to_datetime(df['æ•°æ®æ—¶é—´'])

            # åŸºç¡€æ¸…ç†ï¼šä»…å°†æ—¶é—´è½¬ä¸ºæ—¶é—´æˆ³ï¼Œæ•°å€¼åˆ—åœ¨ç”¨åˆ°æ—¶æŒ‰åˆ—è½¬æ¢
            df = df.copy()

            print(f"æˆåŠŸåŠ è½½æ•°æ®æ–‡ä»¶: {file_path}")
            print(f"æ•°æ®è¡Œæ•°: {len(df)}, åˆ—æ•°: {len(df.columns)}")
            return df

        except Exception as e:
            print(f"åŠ è½½æ•°æ®æ–‡ä»¶å¤±è´¥: {e}")
            return pd.DataFrame()

    def clean_numeric_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """å…¼å®¹æ—§è°ƒç”¨ï¼Œç°ä¸åšå…¨å±€æ¸…æ´—ã€‚"""
        return df

    def _coerce_numeric(self, series: pd.Series) -> pd.Series:
        """å°†åˆ—å®‰å…¨è½¬æ¢ä¸ºæ•°å€¼ï¼Œæ— æ³•è½¬æ¢çš„è®¾ä¸ºNaNï¼Œä¿ç•™åŸé•¿åº¦ã€‚"""
        s = series.astype(str)
        s = s.replace({'--': '0', 'nan': '0'})
        s = s.str.extract(r'(-?\d+\.?\d*)', expand=False)
        s = pd.to_numeric(s, errors='coerce')
        return s

    def _clean_outliers_for_calculation(self, series: pd.Series, column_name: str = "", allow_negative: bool = False) -> pd.Series:
        """
        è®¡ç®—æ—¶æ¸…æ´—å¼‚å¸¸å€¼ï¼Œä¸ä¿®æ”¹åŸå§‹æ•°æ®
        
        å‚æ•°:
        - series: è¦æ¸…æ´—çš„æ•°æ®åˆ—
        - column_name: åˆ—åï¼Œç”¨äºæ—¥å¿—è¾“å‡º
        - allow_negative: æ˜¯å¦å…è®¸è´Ÿå€¼ï¼ˆå‹åŠ›åˆ—ä¿ç•™è´Ÿå€¼ï¼‰
        
        æ¸…æ´—è§„åˆ™:
        1. ç§»é™¤0å€¼
        2. ç§»é™¤è´Ÿå€¼ï¼ˆexceptå‹åŠ›åˆ—ï¼‰
        3. ä½¿ç”¨ç®±å‹å›¾ç§»é™¤æç«¯å¼‚å¸¸å€¼
        """
        if series.empty:
            return series
        
        # é¦–å…ˆè½¬æ¢ä¸ºæ•°å€¼
        cleaned_series = self._coerce_numeric(series).copy()
        original_count = len(cleaned_series)
        
        # è®°å½•æ¸…æ´—å‰çš„æœ‰æ•ˆæ•°æ®æ•°é‡
        valid_before = cleaned_series.notna().sum()
        
        # 1. ç§»é™¤0å€¼
        zero_mask = cleaned_series == 0
        cleaned_series[zero_mask] = np.nan
        zero_removed = zero_mask.sum()
        
        # 2. ç§»é™¤è´Ÿå€¼ï¼ˆå‹åŠ›åˆ—é™¤å¤–ï¼‰
        negative_removed = 0
        if not allow_negative:
            negative_mask = cleaned_series < 0
            cleaned_series[negative_mask] = np.nan
            negative_removed = negative_mask.sum()
        
        # 3. ç®±å‹å›¾å¼‚å¸¸å€¼æ£€æµ‹
        outlier_removed = 0
        valid_data = cleaned_series.dropna()
        if len(valid_data) > 4:  # è‡³å°‘éœ€è¦4ä¸ªæ•°æ®ç‚¹æ‰èƒ½è®¡ç®—å››åˆ†ä½æ•°
            Q1 = valid_data.quantile(0.25)
            Q3 = valid_data.quantile(0.75)
            IQR = Q3 - Q1
            
            # å®šä¹‰å¼‚å¸¸å€¼è¾¹ç•Œ
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            # ç§»é™¤å¼‚å¸¸å€¼
            outlier_mask = (cleaned_series < lower_bound) | (cleaned_series > upper_bound)
            cleaned_series[outlier_mask] = np.nan
            outlier_removed = outlier_mask.sum()
        
        # è®°å½•æ¸…æ´—åçš„æœ‰æ•ˆæ•°æ®æ•°é‡
        valid_after = cleaned_series.notna().sum()
        
        # è¾“å‡ºæ¸…æ´—ç»Ÿè®¡ï¼ˆä»…åœ¨æœ‰æ¸…æ´—æ“ä½œæ—¶ï¼‰
        total_removed = zero_removed + negative_removed + outlier_removed
        if total_removed > 0 and column_name:
            print(f"   æ•°æ®æ¸…æ´— [{column_name}]: ç§»é™¤ {total_removed} ä¸ªå¼‚å¸¸å€¼ "
                  f"(é›¶å€¼:{zero_removed}, è´Ÿå€¼:{negative_removed}, å¼‚å¸¸å€¼:{outlier_removed}) "
                  f"å‰©ä½™æœ‰æ•ˆæ•°æ®: {valid_after}/{original_count}")
        
        return cleaned_series

    def calculate_furnace_temperature(self, df: pd.DataFrame, furnace_no: int) -> pd.Series:
        """è®¡ç®—æŸç‚‰çš„ä»£è¡¨æ¸©åº¦ï¼ˆä¸Šéƒ¨ä¸ä¸­éƒ¨ä¸¤ä¸ªæµ‹ç‚¹çš„å¹³å‡ï¼‰ã€‚è¿”å› Seriesã€‚"""
        mapping = get_field_mapping_for_furnace(furnace_no)
        upper_col = mapping["upper_temp"]
        middle_col = mapping["middle_temp"]
        if upper_col not in df.columns or middle_col not in df.columns:
            return pd.Series([np.nan] * len(df), index=df.index, name=f"furnace_temp_{furnace_no}")
        
        # ä½¿ç”¨æ¸…æ´—åçš„æ•°æ®è®¡ç®—æ¸©åº¦
        upper = self._clean_outliers_for_calculation(df[upper_col], f"{furnace_no}å·ç‚‰ä¸Šéƒ¨æ¸©åº¦")
        middle = self._clean_outliers_for_calculation(df[middle_col], f"{furnace_no}å·ç‚‰ä¸­éƒ¨æ¸©åº¦")
        temp = (upper + middle) / 2.0
        temp.name = f"furnace_temp_{furnace_no}"
        return temp

    def calculate_time_windows(self, df: pd.DataFrame, window_type: str = '5min') -> pd.DataFrame:
        """è®¡ç®—æ—¶é—´çª—å£æ•°æ® (5åˆ†é’Ÿã€1å°æ—¶ã€24å°æ—¶)"""
        if 'æ•°æ®æ—¶é—´' not in df.columns:
            return df

        df_copy = df.copy()
        df_copy.set_index('æ•°æ®æ—¶é—´', inplace=True)

        # åªé€‰æ‹©æ•°å€¼åˆ—è¿›è¡Œé‡é‡‡æ ·
        numeric_cols = df_copy.select_dtypes(include=[np.number]).columns
        df_numeric = df_copy[numeric_cols]

        if window_type == '5min':
            # 5åˆ†é’Ÿçª—å£
            resampled = df_numeric.resample('5T').mean()
        elif window_type == '1hour':
            # 1å°æ—¶çª—å£
            resampled = df_numeric.resample('1H').mean()
        elif window_type == '1day' or window_type == '24hour':
            # 24å°æ—¶çª—å£ï¼ˆæ—¥å‡å€¼ï¼‰
            resampled = df_numeric.resample('24H').mean()
        else:
            return df

        resampled.reset_index(inplace=True)
        return resampled

    def check_low_furnace_temp_warning(self, df: pd.DataFrame) -> List[Dict]:
        """å„ç‚‰5åˆ†é’Ÿå‡å€¼ä½äº850â„ƒé¢„è­¦"""
        events: List[Dict] = []
        df_temp = df.copy()
        for fn in self.furnace_list:
            df_temp[f"furnace_temp_{fn}"] = self.calculate_furnace_temperature(df_temp, fn)
        df_temp.set_index('æ•°æ®æ—¶é—´', inplace=True)
        df_5min = df_temp[[c for c in df_temp.columns if str(c).startswith('furnace_temp_')]].resample('5T').mean().reset_index()
        for fn in self.furnace_list:
            col = f"furnace_temp_{fn}"
            if col not in df_5min.columns:
                continue
            mask = df_5min[col] < NINGBO_WARNING_THRESHOLDS['low_furnace_temp']
            for _, row in df_5min[mask].iterrows():
                events.append({
                    'æ—¶é—´': row['æ•°æ®æ—¶é—´'],
                    'ç‚‰å·': str(fn),
                    'é¢„è­¦/æŠ¥è­¦ç±»å‹': 'é¢„è­¦',
                    'é¢„è­¦/æŠ¥è­¦äº‹ä»¶': 'ç¬æ—¶ä½ç‚‰æ¸©ç„šçƒ§',
                    'é¢„è­¦/æŠ¥è­¦åŒºåˆ†': 'é¢„è­¦'
                })
        return events

    def check_low_furnace_temp_alarm(self, df: pd.DataFrame) -> List[Dict]:
        """å„ç‚‰5åˆ†é’Ÿå‡å€¼ä½äº850â„ƒæŠ¥è­¦"""
        events: List[Dict] = []
        df_temp = df.copy()
        for fn in self.furnace_list:
            df_temp[f"furnace_temp_{fn}"] = self.calculate_furnace_temperature(df_temp, fn)
        df_temp.set_index('æ•°æ®æ—¶é—´', inplace=True)
        df_5min = df_temp[[c for c in df_temp.columns if str(c).startswith('furnace_temp_')]].resample('5T').mean().reset_index()
        for fn in self.furnace_list:
            col = f"furnace_temp_{fn}"
            if col not in df_5min.columns:
                continue
            mask = df_5min[col] < NINGBO_ALARM_THRESHOLDS['low_furnace_temp']
            for _, row in df_5min[mask].iterrows():
                events.append({
                    'æ—¶é—´': row['æ•°æ®æ—¶é—´'],
                    'ç‚‰å·': str(fn),
                    'é¢„è­¦/æŠ¥è­¦ç±»å‹': 'æŠ¥è­¦',
                    'é¢„è­¦/æŠ¥è­¦äº‹ä»¶': 'ä½ç‚‰æ¸©ç„šçƒ§',
                    'é¢„è­¦/æŠ¥è­¦åŒºåˆ†': 'æŠ¥è­¦'
                })
        return events



    def check_high_furnace_temp_warning(self, df: pd.DataFrame) -> List[Dict]:
        """å„ç‚‰1å°æ—¶å¹³å‡æ¸©åº¦>1200/1300â„ƒ é¢„è­¦"""
        warnings: List[Dict] = []

        df_temp = df.copy()
        for fn in self.furnace_list:
            df_temp[f"furnace_temp_{fn}"] = self.calculate_furnace_temperature(df_temp, fn)
        df_temp.set_index('æ•°æ®æ—¶é—´', inplace=True)
        df_1h = df_temp[[c for c in df_temp.columns if str(c).startswith('furnace_temp_')]].resample('1H').mean().reset_index()
        for fn in self.furnace_list:
            col = f"furnace_temp_{fn}"
            if col not in df_1h.columns:
                continue
            very_high = df_1h[col] > NINGBO_WARNING_THRESHOLDS['very_high_furnace_temp']
            high = (df_1h[col] > NINGBO_WARNING_THRESHOLDS['high_furnace_temp']) & (~very_high)
            for _, row in df_1h[very_high].iterrows():
                warnings.append({
                    'æ—¶é—´': row['æ•°æ®æ—¶é—´'],
                    'ç‚‰å·': str(fn),
                    'é¢„è­¦/æŠ¥è­¦ç±»å‹': 'é¢„è­¦',
                    'é¢„è­¦/æŠ¥è­¦äº‹ä»¶': 'ç‚‰è†›æ¸©åº¦è¿‡é«˜',
                    'é¢„è­¦/æŠ¥è­¦åŒºåˆ†': 'é¢„è­¦'
                })
            for _, row in df_1h[high].iterrows():
                warnings.append({
                    'æ—¶é—´': row['æ•°æ®æ—¶é—´'],
                    'ç‚‰å·': str(fn),
                    'é¢„è­¦/æŠ¥è­¦ç±»å‹': 'é¢„è­¦',
                    'é¢„è­¦/æŠ¥è­¦äº‹ä»¶': 'ç‚‰è†›æ¸©åº¦åé«˜',
                    'é¢„è­¦/æŠ¥è­¦åŒºåˆ†': 'é¢„è­¦'
                })
        return warnings

    def check_bag_pressure_warning(self, df: pd.DataFrame) -> List[Dict]:
        """å„ç‚‰å¸ƒè¢‹é™¤å°˜å™¨å‹åŠ›æŸå¤±åé«˜/åä½ é¢„è­¦ï¼ˆå®æ—¶è¿›å…¥-é€€å‡ºäº‹ä»¶ï¼‰"""
        warnings: List[Dict] = []

        # æŒ‰æ—¶é—´æ’åºç¡®ä¿æ­£ç¡®çš„çŠ¶æ€è·Ÿè¸ª
        df_sorted = df.sort_values('æ•°æ®æ—¶é—´')

        for fn in self.furnace_list:
            fmap = get_field_mapping_for_furnace(fn)
            pressure_field = fmap['bag_pressure']
            if pressure_field not in df_sorted.columns:
                continue
            # å‹åŠ›åˆ—å…è®¸è´Ÿå€¼ï¼Œåªæ¸…æ´—é›¶å€¼å’Œæç«¯å¼‚å¸¸å€¼
            series = self._clean_outliers_for_calculation(df_sorted[pressure_field], 
                                                        f"{fn}å·ç‚‰å¸ƒè¢‹å‹å·®", 
                                                        allow_negative=True)
            high_start = None
            low_start = None
            for t, val in zip(df_sorted['æ•°æ®æ—¶é—´'], series):
                if pd.isna(val):
                    continue
                if val > NINGBO_WARNING_THRESHOLDS['bag_pressure_high']:
                    if high_start is None:
                        high_start = t
                elif high_start is not None:
                    warnings.append({
                        'æ—¶é—´': high_start,
                        'ç‚‰å·': str(fn),
                        'é¢„è­¦/æŠ¥è­¦ç±»å‹': 'é¢„è­¦',
                        'é¢„è­¦/æŠ¥è­¦äº‹ä»¶': 'å¸ƒè¢‹é™¤å°˜å™¨å‹åŠ›æŸå¤±åé«˜',
                        'é¢„è­¦/æŠ¥è­¦åŒºåˆ†': 'é¢„è­¦'
                    })
                    high_start = None
                if val < NINGBO_WARNING_THRESHOLDS['bag_pressure_low']:
                    if low_start is None:
                        low_start = t
                elif low_start is not None:
                    warnings.append({
                        'æ—¶é—´': low_start,
                        'ç‚‰å·': str(fn),
                        'é¢„è­¦/æŠ¥è­¦ç±»å‹': 'é¢„è­¦',
                        'é¢„è­¦/æŠ¥è­¦äº‹ä»¶': 'å¸ƒè¢‹é™¤å°˜å™¨å‹åŠ›æŸå¤±åä½',
                        'é¢„è­¦/æŠ¥è­¦åŒºåˆ†': 'é¢„è­¦'
                    })
                    low_start = None
            if high_start is not None:
                warnings.append({
                    'æ—¶é—´': high_start,
                    'ç‚‰å·': str(fn),
                    'é¢„è­¦/æŠ¥è­¦ç±»å‹': 'é¢„è­¦',
                    'é¢„è­¦/æŠ¥è­¦äº‹ä»¶': 'å¸ƒè¢‹é™¤å°˜å™¨å‹åŠ›æŸå¤±åé«˜',
                    'é¢„è­¦/æŠ¥è­¦åŒºåˆ†': 'é¢„è­¦'
                })
            if low_start is not None:
                warnings.append({
                    'æ—¶é—´': low_start,
                    'ç‚‰å·': str(fn),
                'é¢„è­¦/æŠ¥è­¦ç±»å‹': 'é¢„è­¦',
                'é¢„è­¦/æŠ¥è­¦äº‹ä»¶': 'å¸ƒè¢‹é™¤å°˜å™¨å‹åŠ›æŸå¤±åä½',
                'é¢„è­¦/æŠ¥è­¦åŒºåˆ†': 'é¢„è­¦'
            })

        return warnings

    def check_o2_warning(self, df: pd.DataFrame) -> List[Dict]:
        """å„ç‚‰ç„šçƒ§ç‚‰å‡ºå£æ°§å«é‡åé«˜/åä½ é¢„è­¦ï¼ˆå®æ—¶è¿›å…¥-é€€å‡ºäº‹ä»¶ï¼‰"""
        warnings: List[Dict] = []

        # æŒ‰æ—¶é—´æ’åºç¡®ä¿æ­£ç¡®çš„çŠ¶æ€è·Ÿè¸ª
        df_sorted = df.sort_values('æ•°æ®æ—¶é—´')

        for fn in self.furnace_list:
            fmap = get_field_mapping_for_furnace(fn)
            o2_field = fmap['o2']
            if o2_field not in df_sorted.columns:
                continue
            # æ°§å«é‡ä¸å…è®¸è´Ÿå€¼
            series = self._clean_outliers_for_calculation(df_sorted[o2_field], 
                                                        f"{fn}å·ç‚‰æ°§å«é‡")
            high_start = None
            low_start = None
            for t, val in zip(df_sorted['æ•°æ®æ—¶é—´'], series):
                if pd.isna(val):
                    continue
                if val > NINGBO_WARNING_THRESHOLDS['o2_high']:
                    if high_start is None:
                        high_start = t
                elif high_start is not None:
                    warnings.append({
                        'æ—¶é—´': high_start,
                        'ç‚‰å·': str(fn),
                        'é¢„è­¦/æŠ¥è­¦ç±»å‹': 'é¢„è­¦',
                        'é¢„è­¦/æŠ¥è­¦äº‹ä»¶': 'ç„šçƒ§ç‚‰å‡ºå£æ°§å«é‡åé«˜',
                        'é¢„è­¦/æŠ¥è­¦åŒºåˆ†': 'é¢„è­¦'
                    })
                    high_start = None
                if val < NINGBO_WARNING_THRESHOLDS['o2_low']:
                    if low_start is None:
                        low_start = t
                elif low_start is not None:
                    warnings.append({
                        'æ—¶é—´': low_start,
                        'ç‚‰å·': str(fn),
                        'é¢„è­¦/æŠ¥è­¦ç±»å‹': 'é¢„è­¦',
                        'é¢„è­¦/æŠ¥è­¦äº‹ä»¶': 'ç„šçƒ§ç‚‰å‡ºå£æ°§å«é‡åä½',
                        'é¢„è­¦/æŠ¥è­¦åŒºåˆ†': 'é¢„è­¦'
                    })
                    low_start = None
            if high_start is not None:
                warnings.append({
                    'æ—¶é—´': high_start,
                    'ç‚‰å·': str(fn),
                    'é¢„è­¦/æŠ¥è­¦ç±»å‹': 'é¢„è­¦',
                    'é¢„è­¦/æŠ¥è­¦äº‹ä»¶': 'ç„šçƒ§ç‚‰å‡ºå£æ°§å«é‡åé«˜',
                    'é¢„è­¦/æŠ¥è­¦åŒºåˆ†': 'é¢„è­¦'
                })
            if low_start is not None:
                warnings.append({
                    'æ—¶é—´': low_start,
                    'ç‚‰å·': str(fn),
                    'é¢„è­¦/æŠ¥è­¦ç±»å‹': 'é¢„è­¦',
                    'é¢„è­¦/æŠ¥è­¦äº‹ä»¶': 'ç„šçƒ§ç‚‰å‡ºå£æ°§å«é‡åä½',
                    'é¢„è­¦/æŠ¥è­¦åŒºåˆ†': 'é¢„è­¦'
                })

        return warnings

    def check_activated_carbon_warning(self, df: pd.DataFrame) -> List[Dict]:
        """å„ç‚‰æ´»æ€§ç‚­æŠ•åŠ é‡ä¸è¶³é¢„è­¦ï¼ˆå®æ—¶ç›‘æ§ï¼‰"""
        warnings: List[Dict] = []
        
        for fn in self.furnace_list:
            col = f"{fn}å·ç‚‰æ´»æ€§ç‚­å–·å°„é‡"
            if col not in df.columns:
                continue
                
            df_sorted = df.sort_values('æ•°æ®æ—¶é—´')
            # æ´»æ€§ç‚­æŠ•åŠ é‡ä¸å…è®¸è´Ÿå€¼
            series = self._clean_outliers_for_calculation(df_sorted[col], 
                                                        f"{fn}å·ç‚‰æ´»æ€§ç‚­æŠ•åŠ é‡")
            
            # å®æ—¶ç›‘æ§æ´»æ€§ç‚­æŠ•åŠ é‡
            low_start = None
            for t, val in zip(df_sorted['æ•°æ®æ—¶é—´'], series):
                if pd.isna(val):
                    continue
                if val < NINGBO_WARNING_THRESHOLDS['activated_carbon_low']:
                    if low_start is None:
                        low_start = t
                elif low_start is not None:
                    warnings.append({
                        'æ—¶é—´': low_start,
                        'ç‚‰å·': str(fn),
                        'é¢„è­¦/æŠ¥è­¦ç±»å‹': 'é¢„è­¦',
                        'é¢„è­¦/æŠ¥è­¦äº‹ä»¶': 'æ´»æ€§ç‚­æŠ•åŠ é‡ä¸è¶³',
                        'é¢„è­¦/æŠ¥è­¦åŒºåˆ†': 'é¢„è­¦'
                    })
                    low_start = None
            
            # å¤„ç†æœªç»“æŸçš„é¢„è­¦
            if low_start is not None:
                warnings.append({
                    'æ—¶é—´': low_start,
                    'ç‚‰å·': str(fn),
                    'é¢„è­¦/æŠ¥è­¦ç±»å‹': 'é¢„è­¦',
                    'é¢„è­¦/æŠ¥è­¦äº‹ä»¶': 'æ´»æ€§ç‚­æŠ•åŠ é‡ä¸è¶³',
                    'é¢„è­¦/æŠ¥è­¦åŒºåˆ†': 'é¢„è­¦'
                })

        return warnings

    def check_nh3_warning(self, df: pd.DataFrame) -> List[Dict]:
        """æ°¨é€ƒé€¸åé«˜é¢„è­¦ï¼ˆä»…3å·ç‚‰å’Œ6å·ç‚‰æœ‰æ­¤ç›‘æµ‹ç‚¹ï¼‰"""
        warnings: List[Dict] = []
        
        # æ ¹æ®ç‚¹ä½è¡¨ï¼Œåªæœ‰3å·ç‚‰å’Œ6å·ç‚‰æœ‰æ°¨é€ƒé€¸ç›‘æµ‹
        for fn in ["3", "6"]:
            col = f"{fn}å·ç‚‰æ°¨é€ƒé€¸é‡"
            if col not in df.columns:
                continue
                
            # è®¡ç®—å°æ—¶å‡å€¼
            df_temp = df.copy()
            df_temp['æ•°æ®æ—¶é—´'] = pd.to_datetime(df_temp['æ•°æ®æ—¶é—´'])
            df_temp.set_index('æ•°æ®æ—¶é—´', inplace=True)
            
            # æ°¨é€ƒé€¸é‡æ•°æ®æ¸…æ´—
            df_temp[col] = self._clean_outliers_for_calculation(df_temp[col], 
                                                              f"{fn}å·ç‚‰æ°¨é€ƒé€¸é‡")
            df_1h = df_temp[[col]].resample('1H').mean().reset_index()
            
            # æ£€æŸ¥è¶…æ ‡
            for _, row in df_1h.iterrows():
                if pd.isna(row[col]):
                    continue
                if row[col] > NINGBO_WARNING_THRESHOLDS['nh3_warning_limit']:
                    warnings.append({
                        'æ—¶é—´': row['æ•°æ®æ—¶é—´'],
                        'ç‚‰å·': str(fn),
                        'é¢„è­¦/æŠ¥è­¦ç±»å‹': 'é¢„è­¦',
                        'é¢„è­¦/æŠ¥è­¦äº‹ä»¶': 'æ°¨é€ƒé€¸åé«˜',
                        'é¢„è­¦/æŠ¥è­¦åŒºåˆ†': 'é¢„è­¦'
                    })

        return warnings

    def calculate_corrected_concentration(self, measured_conc, measured_o2):
        """è®¡ç®—æ ‡å‡†çŠ¶æ€ä¸‹çš„æµ“åº¦ï¼ˆæŠ˜ç®—ï¼‰"""
        # Ïï¼ˆæ ‡å‡†ï¼‰=Ïï¼ˆå®æµ‹ï¼‰*10/(21-Ïï¼ˆå®æµ‹O2ï¼‰ï¼‰
        
        # å¤„ç†å¼‚å¸¸çš„æ°§å«é‡æ•°æ®ï¼Œé¿å…æŠ˜ç®—å¼‚å¸¸
        o2_cleaned = measured_o2.copy()
        conc_cleaned = measured_conc.copy()
        
        # æ°§å«é‡åˆç†èŒƒå›´æ£€æŸ¥ï¼šæ­£å¸¸æƒ…å†µä¸‹åº”åœ¨4%-15%ä¹‹é—´
        # è¶…å‡ºæ­¤èŒƒå›´çš„æ•°æ®å¯èƒ½æ˜¯ä¼ æ„Ÿå™¨æ•…éšœæˆ–å¼‚å¸¸å·¥å†µ
        invalid_o2_mask = (o2_cleaned <= 2) | (o2_cleaned >= 18) | pd.isna(o2_cleaned)
        
        # æµ“åº¦æ•°æ®æ£€æŸ¥
        invalid_conc_mask = (conc_cleaned < 0) | pd.isna(conc_cleaned)
        
        # åˆå¹¶æ— æ•ˆæ•°æ®æ©ç 
        invalid_mask = invalid_o2_mask | invalid_conc_mask
        
        # è®¡ç®—åˆ†æ¯ï¼Œé¿å…åˆ†æ¯è¿‡å°å¯¼è‡´æŠ˜ç®—å€¼å¼‚å¸¸æ”¾å¤§
        denominator = 21 - o2_cleaned
        # å½“åˆ†æ¯å°äº5æ—¶ï¼ˆæ°§å«é‡>16%ï¼‰ï¼ŒæŠ˜ç®—ç³»æ•°è¿‡å¤§ï¼Œè®¤ä¸ºæ•°æ®å¼‚å¸¸
        small_denominator_mask = denominator < 5.0
        
        # æœ€ç»ˆçš„æ— æ•ˆæ•°æ®æ©ç 
        final_invalid_mask = invalid_mask | small_denominator_mask
        
        # è®¡ç®—æŠ˜ç®—æµ“åº¦
        corrected = pd.Series(index=measured_conc.index, dtype=float)
        valid_mask = ~final_invalid_mask
        
        if valid_mask.any():
            corrected[valid_mask] = conc_cleaned[valid_mask] * 10 / denominator[valid_mask]
        
        # æ— æ•ˆæ•°æ®è®¾ä¸ºNaN
        corrected[final_invalid_mask] = np.nan
        
        return corrected

    def check_pollutant_warning(self, df: pd.DataFrame) -> List[Dict]:
        """å„ç‚‰æ±¡æŸ“ç‰©å°æ—¶å‡å€¼é¢„è­¦ï¼ˆæŠ˜ç®—åï¼‰"""
        warnings: List[Dict] = []
        pollutants = {
            'dust': ('çƒŸæ°”ä¸­é¢—ç²’ç‰©ï¼ˆPMï¼‰æµ“åº¦è¾ƒé«˜', 'dust_warning_limit'),
            'nox': ('çƒŸæ°”ä¸­æ°®æ°§åŒ–ç‰©ï¼ˆNOxï¼‰æµ“åº¦è¾ƒé«˜', 'nox_warning_limit'),
            'so2': ('çƒŸæ°”ä¸­äºŒæ°§åŒ–ç¡«ï¼ˆSOâ‚‚ï¼‰æµ“åº¦è¾ƒé«˜', 'so2_warning_limit'),
            'hcl': ('çƒŸæ°”ä¸­æ°¯åŒ–æ°¢ï¼ˆHClï¼‰æµ“åº¦è¾ƒé«˜', 'hcl_warning_limit'),
            'co': ('çƒŸæ°”ä¸­ä¸€æ°§åŒ–ç¢³ï¼ˆCOï¼‰æµ“åº¦è¾ƒé«˜', 'co_warning_limit')
        }
        for fn in self.furnace_list:
            fmap = get_field_mapping_for_furnace(fn)
            o2_col = fmap['o2']
            if o2_col not in df.columns:
                continue
            
            print(f"   æ£€æŸ¥{fn}å·ç‚‰æ±¡æŸ“ç‰©é¢„è­¦...")
            df_num = pd.DataFrame({'æ•°æ®æ—¶é—´': df['æ•°æ®æ—¶é—´']})
            
            # æ¸…æ´—æ°§å«é‡æ•°æ®
            df_num[o2_col] = self._clean_outliers_for_calculation(df[o2_col], f"{fn}å·ç‚‰O2")
            
            # æ¸…æ´—å„æ±¡æŸ“ç‰©æ•°æ®
            for p_key, _ in pollutants.items():
                p_col = fmap[p_key]
                if p_col in df.columns:
                    df_num[p_col] = self._clean_outliers_for_calculation(df[p_col], f"{fn}å·ç‚‰{p_key.upper()}")
            
            df_num = df_num.set_index('æ•°æ®æ—¶é—´')
            df_1h = df_num.resample('1H').mean().reset_index()
            
            for p_key, (event_name, thresh_key) in pollutants.items():
                p_col = fmap.get(p_key)
                if p_col not in df_1h.columns:
                    continue
                
                # è®¡ç®—æŠ˜ç®—æµ“åº¦
                corrected = self.calculate_corrected_concentration(df_1h[p_col], df_1h[o2_col])
                threshold = NINGBO_WARNING_THRESHOLDS[thresh_key]
                mask = corrected > threshold
                
                # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºè®¡ç®—è¿‡ç¨‹
                if mask.any():
                    for idx, (_, row) in enumerate(df_1h[mask].iterrows()):
                        original_conc = row[p_col]
                        o2_value = row[o2_col]
                        corrected_value = corrected.iloc[df_1h.index[df_1h[mask]].get_loc(row.name)]
                        print(f"     {fn}å·ç‚‰{p_key.upper()}é¢„è­¦: åŸå§‹æµ“åº¦={original_conc:.2f}, O2={o2_value:.2f}%, "
                              f"æŠ˜ç®—å={corrected_value:.2f}, é˜ˆå€¼={threshold}")
                
                mask = corrected > threshold
                for _, row in df_1h[mask].iterrows():
                    warnings.append({
                        'æ—¶é—´': row['æ•°æ®æ—¶é—´'],
                        'ç‚‰å·': str(fn),
                        'é¢„è­¦/æŠ¥è­¦ç±»å‹': 'é¢„è­¦',
                        'é¢„è­¦/æŠ¥è­¦äº‹ä»¶': event_name,
                        'é¢„è­¦/æŠ¥è­¦åŒºåˆ†': 'é¢„è­¦'
                    })
        return warnings

    def check_pollutant_alarm(self, df: pd.DataFrame) -> List[Dict]:
        """å„ç‚‰æ±¡æŸ“ç‰©æ—¥å‡å€¼æ’æ”¾è¶…æ ‡æŠ¥è­¦ï¼ˆæŠ˜ç®—åï¼‰"""
        alarms: List[Dict] = []
        pollutants = {
            'dust': ('çƒŸæ°”ä¸­é¢—ç²’ç‰©ï¼ˆPMï¼‰æ’æ”¾è¶…æ ‡', 'dust_alarm_limit'),
            'nox': ('çƒŸæ°”ä¸­æ°®æ°§åŒ–ç‰©ï¼ˆNOxï¼‰æ’æ”¾è¶…æ ‡', 'nox_alarm_limit'),
            'so2': ('çƒŸæ°”ä¸­äºŒæ°§åŒ–ç¡«ï¼ˆSOâ‚‚ï¼‰æ’æ”¾è¶…æ ‡', 'so2_alarm_limit'),
            'hcl': ('çƒŸæ°”ä¸­æ°¯åŒ–æ°¢ï¼ˆHClï¼‰æ’æ”¾è¶…æ ‡', 'hcl_alarm_limit'),
            'co': ('çƒŸæ°”ä¸­ä¸€æ°§åŒ–ç¢³ï¼ˆCOï¼‰æ’æ”¾è¶…æ ‡', 'co_alarm_limit')
        }
        for fn in self.furnace_list:
            fmap = get_field_mapping_for_furnace(fn)
            o2_col = fmap['o2']
            if o2_col not in df.columns:
                continue
            
            print(f"   æ£€æŸ¥{fn}å·ç‚‰æ±¡æŸ“ç‰©æŠ¥è­¦...")
            df_num = pd.DataFrame({'æ•°æ®æ—¶é—´': df['æ•°æ®æ—¶é—´']})
            
            # æ¸…æ´—æ°§å«é‡æ•°æ®
            df_num[o2_col] = self._clean_outliers_for_calculation(df[o2_col], f"{fn}å·ç‚‰O2")
            
            # æ¸…æ´—å„æ±¡æŸ“ç‰©æ•°æ®
            for p_key, _ in pollutants.items():
                p_col = fmap[p_key]
                if p_col in df.columns:
                    df_num[p_col] = self._clean_outliers_for_calculation(df[p_col], f"{fn}å·ç‚‰{p_key.upper()}")
            
            df_num = df_num.set_index('æ•°æ®æ—¶é—´')
            df_daily = df_num.resample('24H').mean().reset_index()
            
            for p_key, (event_name, threshold_key) in pollutants.items():
                p_col = fmap.get(p_key)
                if p_col not in df_daily.columns:
                    continue
                
                # è®¡ç®—æŠ˜ç®—æµ“åº¦
                corrected = self.calculate_corrected_concentration(df_daily[p_col], df_daily[o2_col])
                threshold = NINGBO_ALARM_THRESHOLDS[threshold_key]
                mask = corrected > threshold
                
                # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºè®¡ç®—è¿‡ç¨‹
                if mask.any():
                    for idx, (_, row) in enumerate(df_daily[mask].iterrows()):
                        original_conc = row[p_col]
                        o2_value = row[o2_col]
                        corrected_value = corrected.iloc[df_daily.index[df_daily[mask]].get_loc(row.name)]
                        print(f"     âš ï¸  {fn}å·ç‚‰{p_key.upper()}æŠ¥è­¦: æ—¥å‡åŸå§‹æµ“åº¦={original_conc:.2f}, "
                              f"æ—¥å‡O2={o2_value:.2f}%, æŠ˜ç®—å={corrected_value:.2f}, é˜ˆå€¼={threshold}")
                
                mask = corrected > threshold
                for _, row in df_daily[mask].iterrows():
                    alarms.append({
                        'æ—¶é—´': row['æ•°æ®æ—¶é—´'],
                        'ç‚‰å·': str(fn),
                        'é¢„è­¦/æŠ¥è­¦ç±»å‹': 'æŠ¥è­¦',
                        'é¢„è­¦/æŠ¥è­¦äº‹ä»¶': event_name,
                        'é¢„è­¦/æŠ¥è­¦åŒºåˆ†': 'æŠ¥è­¦'
                    })
        return alarms

    def process_data(self, file_path: str, output_dir: str = None) -> pd.DataFrame:
        """å¤„ç†æ•°æ®å¹¶ç”Ÿæˆé¢„è­¦æŠ¥å‘Š"""
        # åŠ è½½æ•°æ®
        df = self.load_data(file_path)
        if df.empty:
            return pd.DataFrame()

        # æ¸…ç©ºä¹‹å‰çš„é¢„è­¦äº‹ä»¶
        self.warning_events = []

        print(f"\næ£€æŸ¥å®æ³¢ä¸–è´¸ç„šçƒ§ç‚‰é¢„è­¦/æŠ¥è­¦ (3-6å·ç‚‰)...")

        # === é¢„è­¦è§„åˆ™ ===
        low_temp_warnings = self.check_low_furnace_temp_warning(df)
        self.warning_events.extend(low_temp_warnings)
        print(f"ç¬æ—¶ä½ç‚‰æ¸©é¢„è­¦: {len(low_temp_warnings)} æ¡")

        high_temp_warnings = self.check_high_furnace_temp_warning(df)
        self.warning_events.extend(high_temp_warnings)
        print(f"é«˜ç‚‰æ¸©é¢„è­¦: {len(high_temp_warnings)} æ¡")

        pressure_warnings = self.check_bag_pressure_warning(df)
        self.warning_events.extend(pressure_warnings)
        print(f"å‹åŠ›é¢„è­¦: {len(pressure_warnings)} æ¡")

        o2_warnings = self.check_o2_warning(df)
        self.warning_events.extend(o2_warnings)
        print(f"æ°§å«é‡é¢„è­¦: {len(o2_warnings)} æ¡")

        pollutant_warnings = self.check_pollutant_warning(df)
        self.warning_events.extend(pollutant_warnings)
        print(f"æ±¡æŸ“ç‰©é¢„è­¦: {len(pollutant_warnings)} æ¡")

        # æ´»æ€§ç‚­æŠ•åŠ é‡é¢„è­¦
        carbon_warnings = self.check_activated_carbon_warning(df)
        self.warning_events.extend(carbon_warnings)
        print(f"æ´»æ€§ç‚­æŠ•åŠ é‡é¢„è­¦: {len(carbon_warnings)} æ¡")

        # æ°¨é€ƒé€¸é¢„è­¦
        nh3_warnings = self.check_nh3_warning(df)
        self.warning_events.extend(nh3_warnings)
        print(f"æ°¨é€ƒé€¸é¢„è­¦: {len(nh3_warnings)} æ¡")

        # === æŠ¥è­¦è§„åˆ™ ===
        low_temp_alarms = self.check_low_furnace_temp_alarm(df)
        self.warning_events.extend(low_temp_alarms)
        print(f"ä½ç‚‰æ¸©æŠ¥è­¦: {len(low_temp_alarms)} æ¡")

        pollutant_alarms = self.check_pollutant_alarm(df)
        self.warning_events.extend(pollutant_alarms)
        print(f"æ±¡æŸ“ç‰©æŠ¥è­¦: {len(pollutant_alarms)} æ¡")

        # è½¬æ¢ä¸ºDataFrame
        if self.warning_events:
            warning_df = pd.DataFrame(self.warning_events)
            warning_df = warning_df.sort_values('æ—¶é—´')

            print(f"\nå…±æ£€æµ‹åˆ° {len(warning_df)} æ¡é¢„è­¦äº‹ä»¶")

            furnace_stats = warning_df['ç‚‰å·'].value_counts().sort_index()
            print("å„ç‚‰é¢„è­¦åˆ†å¸ƒ:")
            for furnace, count in furnace_stats.items():
                print(f"  {furnace}å·ç‚‰: {count} æ¡é¢„è­¦")

            if output_dir:
                self.save_warning_report(warning_df, output_dir, file_path)

            return warning_df
        else:
            print("\næœªæ£€æµ‹åˆ°é¢„è­¦äº‹ä»¶")
            return pd.DataFrame()

    def save_warning_report(self, warning_df: pd.DataFrame, output_dir: str, input_file: str):
        """ä¿å­˜é¢„è­¦æŠ¥è­¦æŠ¥å‘Š"""
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        base_name = os.path.splitext(os.path.basename(input_file))[0]
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        # ä¿å­˜Excelæ ¼å¼
        excel_file = os.path.join(output_dir, f"{base_name}_å®æ³¢ä¸–è´¸é¢„è­¦æŠ¥è­¦æŠ¥å‘Š_{timestamp}.xlsx")
        warning_df.to_excel(excel_file, index=False)
        print(f"ğŸ“Š é¢„è­¦æŠ¥è­¦æŠ¥å‘Šå·²ä¿å­˜: {excel_file}")

        # ä¿å­˜CSVæ ¼å¼
        csv_file = os.path.join(output_dir, f"{base_name}_å®æ³¢ä¸–è´¸é¢„è­¦æŠ¥è­¦æŠ¥å‘Š_{timestamp}.csv")

        if 'é¢„è­¦/æŠ¥è­¦åŒºåˆ†' not in warning_df.columns:
            warning_df['é¢„è­¦/æŠ¥è­¦åŒºåˆ†'] = warning_df['é¢„è­¦/æŠ¥è­¦ç±»å‹']

        required_columns = ['æ—¶é—´', 'ç‚‰å·', 'é¢„è­¦/æŠ¥è­¦ç±»å‹', 'é¢„è­¦/æŠ¥è­¦äº‹ä»¶', 'é¢„è­¦/æŠ¥è­¦åŒºåˆ†']
        template_df = warning_df[required_columns].copy()
        template_df.to_csv(csv_file, index=False, encoding='utf-8-sig')
        print(f"ğŸ“‹ CSVæŠ¥å‘Šå·²ä¿å­˜: {csv_file}")

        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        stats_file = os.path.join(output_dir, f"{base_name}_å®æ³¢ä¸–è´¸é¢„è­¦æŠ¥è­¦ç»Ÿè®¡_{timestamp}.txt")
        with open(stats_file, 'w', encoding='utf-8') as f:
            f.write(f"å®æ³¢ä¸–è´¸åƒåœ¾ç„šçƒ§é¢„è­¦æŠ¥è­¦ç»Ÿè®¡æŠ¥å‘Š\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ•°æ®æ–‡ä»¶: {input_file}\n")
            f.write(f"æ€»äº‹ä»¶æ•°é‡: {len(warning_df)}\n\n")

            type_stats = warning_df['é¢„è­¦/æŠ¥è­¦ç±»å‹'].value_counts()
            f.write("äº‹ä»¶ç±»å‹ç»Ÿè®¡:\n")
            for event_type, count in type_stats.items():
                f.write(f"  {event_type}: {count} æ¡\n")

            event_stats = warning_df['é¢„è­¦/æŠ¥è­¦äº‹ä»¶'].value_counts()
            f.write("\näº‹ä»¶è¯¦ç»†ç»Ÿè®¡:\n")
            for event, count in event_stats.items():
                f.write(f"  {event}: {count} æ¡\n")

            f.write(f"\n1å·ç‚‰æ€»äº‹ä»¶æ•°: {len(warning_df)} æ¡\n")

        print(f"ğŸ“ˆ ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜: {stats_file}")

def main():
    """ä¸»å‡½æ•° - æ”¯æŒå‘½ä»¤è¡Œå’Œç›´æ¥è¿è¡Œ"""
    import sys

    DEFAULT_INPUT_FILE = "å®å¾·ä¸–è´¸/2025å¹´1æœˆ/20250103.xlsx"  # é»˜è®¤è¾“å…¥æ–‡ä»¶
    DEFAULT_OUTPUT_DIR = "å®å¾·ä¸–è´¸/é¢„è­¦æ–‡ä»¶è¾“å‡º"  # é»˜è®¤è¾“å‡ºç›®å½•

    if len(sys.argv) >= 2:
        input_file = sys.argv[1]
        output_dir = sys.argv[2] if len(sys.argv) > 2 else DEFAULT_OUTPUT_DIR
    else:
        print("ğŸš€ ç›´æ¥è¿è¡Œæ¨¡å¼")
        print("ğŸ’¡ æç¤º: å¯ä»¥ä¿®æ”¹ä»£ç ä¸­çš„DEFAULT_INPUT_FILEå˜é‡æ¥æŒ‡å®šè¦åˆ†æçš„æ–‡ä»¶")
        print("ğŸ’¡ æç¤º: ä½¿ç”¨ python shishi_data_yujing_gz.py <æ–‡ä»¶è·¯å¾„> åˆ†ææŒ‡å®šæ–‡ä»¶")

        input_file = DEFAULT_INPUT_FILE
        output_dir = DEFAULT_OUTPUT_DIR

        print(f"ğŸ“ ä½¿ç”¨é»˜è®¤è¾“å…¥æ–‡ä»¶: {input_file}")

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_file):
        print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨ - {input_file}")
        print("è¯·ä¿®æ”¹ä»£ç ä¸­çš„DEFAULT_INPUT_FILEå˜é‡æˆ–ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°")
        return

    # åˆ›å»ºé¢„è­¦ç³»ç»Ÿå®ä¾‹
    print("\nğŸ”§ åˆ›å»ºå®æ³¢ä¸–è´¸é¢„è­¦ç³»ç»Ÿå®ä¾‹...")
    warning_system = WasteIncinerationWarningSystemNingbo()

    # å¤„ç†æ•°æ®
    print(f"ğŸ“Š å¼€å§‹å¤„ç†æ•°æ®æ–‡ä»¶: {input_file}")
    try:
        warning_df = warning_system.process_data(input_file, output_dir)

        if not warning_df.empty:
            print(f"\nâœ… é¢„è­¦å¤„ç†å®Œæˆ! è¾“å‡ºç›®å½•: {output_dir}")
            print(f"ğŸ“Š æ€»è®¡æ£€æµ‹åˆ° {len(warning_df)} æ¡é¢„è­¦æŠ¥è­¦äº‹ä»¶")

            # æ˜¾ç¤ºäº‹ä»¶ç±»å‹ç»Ÿè®¡
            type_stats = warning_df['é¢„è­¦/æŠ¥è­¦ç±»å‹'].value_counts()
            print("\nğŸ“ˆ äº‹ä»¶ç±»å‹ç»Ÿè®¡:")
            for event_type, count in type_stats.items():
                print(f"  {event_type}: {count} æ¡")

            # æ˜¾ç¤ºå‰å‡ æ¡äº‹ä»¶
            print(f"\nğŸ“‹ å‰5æ¡äº‹ä»¶:")
            for i, (_, row) in enumerate(warning_df.head().iterrows()):
                print(f"  {i+1}. {row['æ—¶é—´']} - {row['é¢„è­¦/æŠ¥è­¦äº‹ä»¶']} ({row['é¢„è­¦/æŠ¥è­¦ç±»å‹']})")
        else:
            print("\nâœ… æ•°æ®å¤„ç†å®Œæˆï¼Œæœªå‘ç°é¢„è­¦æŠ¥è­¦äº‹ä»¶ã€‚")

    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
